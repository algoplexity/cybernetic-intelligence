# CIv7-ECA: Structural Break Detection via Symbolic Substrate Compression and Fault Geometry

**Hypothesis**
Structural breaks in univariate time series can be robustly detected by encoding the input as symbolic sequences (e.g., via permutation entropy, delta-sign encoding), evolving these sequences through Elementary Cellular Automata (ECA), and analysing the resulting **2D symbolic evolution as an algorithmic and topological substrate**. This substrate exposes **latent causal dynamics**, **semantic irregularities**, and **algorithmic fault lines**. These transitions manifest as discontinuities in:

* **Algorithmic compressibility** (e.g., via BDM or CTM)
* **Joint compression failure** (predictive collapse à la Sutskever)
* **Torsion and persistent topological invariants** (Walch)
* **Motif circuit reconfiguration and symbolic attention rewiring** (Circuit Tracer analogy)
* **Local motif entropy shifts** and permutation entropy gradients
* **Collapse of symbolic attractors** and bifurcation points in 2D dynamics
* **Failure of logical boundary preservation** (torsion and curvature loss per Hodge)
* **Reality signal collapse** (based on perceptual vs. imagined structure loss)
* **Prediction breakdown at the edge of chaos** (Zhang et al.)
* **Simulability gaps in world models built from symbolic evolution** (Ha & Schmidhuber)
* **Emergence of intelligent representation capacity from non-intelligent but complex symbolic sources** (Zhang et al.)
* **Reversible inference layers from local symbolic MCMC transitions** (Vivier-Ardisson et al.)
* **Self-replicating symbolic agent emergence in open-ended improvement loops** (Darwin Gödel Machine)
* **LLM-guided symbolic alpha search and functional meta-discovery** (AlphaEvolve, DeepMind)
* **Confidence gradient formation and semantic signal modulation in hallucination-prone regions** (Bouchard & Chauhan)

The symbolic substrate is not merely representational—it is **causally expressive**, revealing failure surfaces where data-driven structure collapses. The substrate thus functions as a model-agnostic detection layer for algorithmic, topological, and semantic regime shifts.

---

**Rationale**

* **Sutskever's theory of unsupervised learning** demonstrates that compression is prediction; joint compression failure between segments of symbolic time series reflects true structural discontinuity.
* **Walch's torsion analysis** confirms that fragile, high-dimensional topological signatures collapse under even minor perturbations—making torsion an excellent early-warning detector.
* **Sakabe et al.** show that BDM captures algorithmic changes in symbolic representations better than Shannon entropy, making it ideal for symbolic phase-shift detection in ECA substrates.
* **Anthropic’s Circuit Tracer** demonstrates that influence graphs can localise semantic drift in LLMs; we extend this metaphor to symbolic motifs in ECA evolution, where rewiring of symbolic circuits signals change.
* **Grosse et al.** provide a geometric generalisation of Occam’s Razor showing how singular models can have negative complexity; in symbolic substrates, degeneracy or symmetry in motif transitions may represent low-complexity zones that are broken by regime change.
* **Grünwald & Roos (2019)** offer a modern MDL theory emphasizing model selection and predictive robustness via universal distributions. Their use of NML and luckiness-weighted codes supports our treatment of symbolic substrates as **sequential predictors** whose compressibility divergence reflects structural breakpoints. Particularly relevant are:

  * MDL's shift from coding to inductive inference via log-loss
  * NML as the robust baseline predictor (maximin regret minimizer)
  * The role of **luckiness functions** in capturing prior motif structure, and
  * The **switch distribution** to model abrupt change between regimes.
* **BrightStar Labs (EMs)** use CA-like substrates for generalisation via initial state optimization. Our use is inverse: symbolic inputs are evolved under fixed rules, making the substrate a diagnostic canvas rather than a policy machine.
* **OpenThoughts (2024)** emphasises the critical role of structured symbolic input for training high-fidelity reasoning systems; our substrate acts as a pre-LLM semantic preprocessor.
* **Dijkstra et al. (2025)** on the neural basis of reality monitoring shows that additive imagery-perception confusion maps directly onto symbolic substrate failures, where local motif reinforcement mimics perceptual signal misclassification.
* **Zhang et al. (2024)** explore **intelligence at the edge of chaos**, showing that exposure to structured yet unpredictable systems (like Class IV ECAs) enables models to develop generalisable reasoning capabilities. ECA-evolved substrates inhabit this complexity sweet spot—structured enough to encode causality, complex enough to force predictive reasoning.
* **Ha & Schmidhuber's World Models** highlight the importance of a compressed latent space capable of simulating the environment. ECA substrates can similarly act as **symbolic generative scaffolds**, allowing detection of divergences between real and simulated dynamics. These hallucinated substrates can be used to train symbolic controllers in "dreamtime" analogous to latent-space reinforcement learning.
* **Vivier-Ardisson et al. (2025)** demonstrate that symbolic substrates based on local MCMC layers can serve as reversible reasoning scaffolds. The symbolic dynamics of ECAs can be understood as heuristic proposal distributions whose temperature-driven collapse or bifurcation traces the onset of algorithmic phase transitions. This introduces the ability to model attractor shifts and regime flips through a differentiable lens, integrating top-down learning pressures into bottom-up symbolic substrate evolution.
* **Darwin Gödel Machine (2024)** introduces a framework for autonomous, open-ended self-improvement through empirical feedback loops. The symbolic agent maintains a lineage of increasingly capable variants via archive-driven selection and self-modification, mirroring symbolic motif evolution within the ECA substrate. Regime shifts in the agent's internal capabilities correspond to compositional symbolic restructuring, akin to bifurcation in the ECA field.
* **AlphaEvolve (2025)** demonstrates the potential of LLM-guided, feedback-grounded evolutionary code improvement. Within symbolic substrates, Alpha-style LLM agents can discover compressible, high-performance motif configurations that exceed static design patterns. Evolutionary variation and runtime evaluation drive convergence toward symbolic motifs that maximise structural fitness, reasoning utility, or predictive accuracy—each of which maps to fault boundary formation in our hypothesis.
* **Bouchard & Chauhan (2025)** contribute a framework for zero-resource hallucination detection using ensemble uncertainty quantification techniques (black-box, white-box, and LLM-as-a-Judge). Symbolic substrates enriched with volatility measures (e.g., semantic entropy, response divergence) serve as hallucination predictors. Divergence in local motif confidence becomes a proxy for regime instability, reinforcing the use of symbolic substrates for **real-time, zero-ground-truth change detection**.

---

**Supporting Literature**

* Zenil et al. – Algorithmic Information Dynamics
* BrightStar Labs (2025) – Emergent Models and symbolic computation substrates
* Sakabe et al. – Attribution Drift from symbolic perturbations
* Maria Walch (2024) – Torsion as topological signal in high-dimensional symbolic dynamics
* Ilya Sutskever (2024) – Unsupervised Learning as Compression (joint vs. separate encoding)
* Anthropic (2025) – Circuit Tracer and latent attribution path rewiring
* Grosse et al. – Occam’s Razor in Geometric-Algorithmic Deep Models
* Peter Grünwald & Teemu Roos – MDL Revisited
* OpenThoughts (2024) – Recipes for compositional reasoning over symbolic sequences
* Dijkstra et al. (2025) – Neural Basis for Reality Signal Formation and Binary Judgement
* Zhang et al. – Intelligence at the Edge of Chaos
* Ha & Schmidhuber – World Models and Evolutionary Symbol Machines
* Zhang et al. – DGM and Self-Modifying Substrate Architectures
* Vivier-Ardisson et al. – Physics of Learning & MCMC Layers
* DeepMind (2025) – AlphaEvolve: LLM-supervised evolutionary algorithm discovery
* Bouchard & Chauhan (2025) – Uncertainty Quantification for Hallucination Detection in LLMs

---

This revised CIv7-ECA hypothesis reflects a rigorous, modular approach to structural break detection, interpreting symbolic evolution not only as a computational mechanism, but as a **causal, geometric, and topological lens** on hidden discontinuities in dynamic systems.
