# -*- coding: utf-8 -*-
"""MScFE 690 G3614 2n1Rules.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XaMjhalj8Pgf-t68EDKMjqX10VNL1MPc

# **MScFE 690 Capstone**

## Applying Algorithmic Generative Modeling for Detecting High Order Dependencies between stocks
Cellular Automata as Algorithmic Generative Model using Algorithmic Information Dynamics for patterns matching in the study of Cross-Sectional Ranking and High Order Dependencies between stocks

Key Components of this study
* Algorithmic Complexity and Block Decomposition Method
* Minimal Information Loss Methods
* Cellular Automata
* Genetic Algorithms

Key Objectives are:
1. Determine if Elementary Cellular Automata (ECA) rules can model the complex relationships between stocks
2. Identify the ECA rule(s) that best match the actual market data according to MILS algorithm mentioned below
3. Gain insight into the patterns and rules that govern the market behavior

## Timer Decorator
"""

import time

def timer(func):
  def wrapper(*args, **kwargs):
    start = time.time()
    result = func(*args, **kwargs)
    end = time.time()
    elapsed = (end-start)/60
    print(f"{func.__name__} took {elapsed:.2f} mins")
    return result
  return wrapper

"""## Connect to Google Drive"""

from google.colab import drive
drive.mount('/content/drive')

cd /content/drive/MyDrive/Colab Notebooks/Capstone/eca_images_1r

"""## 1. Data Engineering
We have selected 8 stocks and collected their daily price change for a continuous period of 192 days. We encode the sign and magnitude of change using 1 bit and 3 bit respectively. Therefore, we have 32 bits encoded price change data for the rest of our analysis. We name this 2D binary array as O for observed market data.

### Download Prices from YF
"""

#alternatively it is easier to retrieve daily closing prices from Yahoo Finance
import pandas as pd
import yfinance as yf
import datetime

# Define start and end dates
start_date = datetime.datetime(2018, 1, 1)
end_date = datetime.datetime(2023, 6, 30)

# Define list of stock tickers
#tickers = ['AAPL', 'GOOG', 'MSFT', 'AMZN', 'META', 'TSLA', 'NVDA', 'JPM']
tickers = ['AAPL', 'BA', 'CAT', 'DIS', 'GE', 'IBM', 'MSFT', 'TSLA']

# Retrieve data for each stock ticker
data = yf.download(tickers, start=start_date, end=end_date)['Adj Close']

# Print the first 5 rows of the data
print(data.head())
# Print the last 5 rows of the data
print(data.tail())

df1 = data

# Calculate percent change across all 8 selected stocks
df1['AAPL Change'] = df1['AAPL'].pct_change()
df1['BA Change'] = df1['BA'].pct_change()
df1['CAT Change'] = df1['CAT'].pct_change()
df1['DIS Change'] = df1['DIS'].pct_change()
df1['GE Change'] = df1['GE'].pct_change()
df1['IBM Change'] = df1['IBM'].pct_change()
df1['MSFT Change'] = df1['MSFT'].pct_change()
df1['TSLA Change'] = df1['TSLA'].pct_change()

df_cleaned = df1

def get_magnitude(change):
    if abs(change) <= 0.02:
        return '000'
    elif abs(change) <= 0.04:
        return '001'
    elif abs(change) <= 0.08:
        return '010'
    elif abs(change) <= 0.12:
        return '011'
    elif abs(change) <= 0.16:
        return '100'
    elif abs(change) <= 0.20:
        return '101'
    elif abs(change) <= 0.24:
        return '110'
    else:
        return '111'

def get_code(change):
    if change >= 0:
        sign = '1'
        mag = get_magnitude(change)
    else:
        sign = '0'
        change *= -1
        mag = get_magnitude(change)
    return sign + mag

strings = []
for date, aapl, ba, cat, dis, ge ,ibm, msft, tsla in zip(df_cleaned.index.date,
    df_cleaned['AAPL Change'], df_cleaned['BA Change'],
    df_cleaned['CAT Change'], df_cleaned['DIS Change'],
    df_cleaned['GE Change'], df_cleaned['IBM Change'],
    df_cleaned['MSFT Change'], df_cleaned['TSLA Change']):

    aapl_code = get_code(aapl)
    ba_code = get_code(ba)
    cat_code = get_code(cat)
    dis_code = get_code(dis)
    ge_code = get_code(ge)
    ibm_code = get_code(ibm)
    msft_code = get_code(msft)
    tsla_code = get_code(tsla)

    strings.append(aapl_code + ba_code + cat_code + dis_code +
                   ge_code + ibm_code + msft_code + tsla_code)

# Defined constant for encoding purposes
DATE_LEN = 10
TOTAL_LEN = 192

"""### Encode Observed Market Data"""

eca_input_string = strings[0]

import numpy as np

study_strings = strings[0:TOTAL_LEN]

encoded_strings = []

for i in range(len(study_strings)):
    s = study_strings[i]
    encoded_data = s
    encoded_strings.append(encoded_data)

# Convert to 2D numpy array
observed_data_arr = np.array([list(s) for s in encoded_strings]).astype(int)

observed_data_arr

observed_data_arr.shape

"""### Count input images files"""

import os

# Function to get list of subfolders
def get_subfolder_list(folder_path):

  subfolders = []

  for entry in os.listdir(folder_path):

    full_path = os.path.join(folder_path, entry)

    if os.path.isdir(full_path):
      subfolders.append(full_path)

  return subfolders

import glob
import os

def get_filenames(folder):

  file_count = 0
  filenames = []

  name_patterns = [
    'eca_images*.pkl',
    'eca_images*_*.pkl',
    'eca_images*_*_*.pkl'
  ]

  for pattern in name_patterns:
    files = glob.glob(os.path.join(folder, pattern))
    filenames.extend(files)
    file_count += len(files)

  print(f"Total files in {folder}: {file_count}")

  unique_filenames = set(filenames)
  return unique_filenames

import os
import glob

def count_unique_files(folder_path):

  file_count = 0

  subfolders = get_subfolder_list(folder_path)
  print(f"count : subfolders : {subfolders}")
  for subfolder in subfolders:

    filenames = get_filenames(subfolder)

    file_count += len(filenames)

  return file_count

# Usage
# folder_path = '/path/to/folder'
# total_files = count_unique_files(folder_path)
# print(f"Total matching unique files: {total_files}")

folder_path = '/content/drive/MyDrive/Colab Notebooks/Capstone/eca_images_1r'
num_files = count_unique_files(folder_path)
print(f"Number of unique files: {num_files}")

# superceded
import glob
import os

filenames = []
filenames.extend(glob.glob('eca_images*.pkl'))
filenames.extend(glob.glob('eca_images*_*.pkl'))
filenames.extend(glob.glob('eca_images*_*_*.pkl'))

unique_filenames = set(filenames)

num_files = len(unique_filenames)

print(f"Number of unique files: {num_files}")

unique_filenames = num_files
unique_filenames

"""### Load ECA Images"""

import re
import os

name_patterns = [
  r'eca_images(?P<rule1>[0-9]{1,3}).pkl',
  r'eca_images(?P<rule1>[0-9]{1,3})_(?P<rule2>[0-9]{1,3}).pkl',
  r'eca_images(?P<rule1>[0-9]{1,3})_(?P<rule2>[0-9]{1,3})_(?P<rule3>[0-9]{1,3}).pkl'
]

def parse_filename(filename):

  filename = os.path.basename(filename)

  for pattern in name_patterns:
    match = re.match(pattern, filename)
    if match:
      rule1 = int(match.group("rule1"))

      if "rule2" in match.groupdict():
        rule2 = int(match.group("rule2"))
      else:
        rule2 = None

      if "rule3" in match.groupdict():
        rule3 = int(match.group("rule3"))
      else:
        rule3 = None

      return (rule1, rule2, rule3)

  return (None, None, None)

import pickle
import numpy as np

eca_images = {}
total_images = 0

folder_path = '/content/drive/MyDrive/Colab Notebooks/Capstone/eca_images_1r'

unique_filenames = get_filenames(folder_path)

for filename in unique_filenames:

  # Extract rules from filename
  rule1, rule2, rule3 = parse_filename(filename)
  print(f'rule1 rule2 rule3 : {rule1} {rule2} {rule3}')


  with open(filename, 'rb') as f:
    ca = pickle.load(f)

  # Convert to NumPy array if needed
  if not isinstance(ca, np.ndarray):
    ca = np.array(ca)

  # Store array under rule keys
  if rule3 is not None:
    if rule1 not in eca_images:
      eca_images[rule1] = {}
    if rule2 not in eca_images[rule1]:
      eca_images[rule1][rule2] = {}
    eca_images[rule1][rule2][rule3] = ca
    total_images += 1


  elif rule2 is not None:
    if rule1 not in eca_images:
      eca_images[rule1] = {}
    eca_images[rule1][rule2] = ca
    total_images += 1

  else:
    eca_images[rule1] = ca
    total_images += 1

  ca = np.array(ca)[:64,:]

print(f'Total number of eca images: {total_images}')

total_images = 0

for x in range(256):
  for y in range(256):
    try:
      if isinstance(eca_images[x][y], np.ndarray):
        total_images += 1
    except KeyError as e:
      print(f"Key ({x}, {y}) not found in eca_images")


print(f'Total number of eca images: {total_images}')

print(rule1, rule2, rule3)

eca_images[255].shape

len(eca_images[10])

"""#### Testing subset of images"""

import pickle
import numpy as np

eca_images = {}
min_rule1 = 255
max_rule1 = 0
min_rule2 = None
max_rule2 = None
min_rule3 = None
max_rule3 = None

for filename in unique_filenames:

  # Extract rules from filename
  rule1, rule2, rule3 = parse_filename(filename)
  print(f'rule1 rule2 rule3 : {rule1} {rule2} {rule3}')

  if rule1 < min_rule1:
    min_rule1 = rule1
  elif rule1 > max_rule1:
    max_rule1 = rule1

  if rule2 != None:
    if min_rule2 == None:
      min_rule2 = rule2
    elif rule2 < min_rule2:
      min_rule2 = rule2
    elif max_rule2 == None:
      max_rule2 = rule2
    elif rule2 > max_rule2:
      max_rule2 = rule2

  if rule3 != None:
    if min_rule3 == None:
      min_rule3 = rule3
    elif rule3 < min_rule3:
      min_rule3 = rule3
    elif max_rule3 == None:
      max_rule3 = rule3
    elif rule3 > max_rule3:
      max_rule3 = rule3

  with open(filename, 'rb') as f:
    ca = pickle.load(f)

  # Convert to NumPy array if needed
  if not isinstance(ca, np.ndarray):
    ca = np.array(ca)

  # Store array under rule keys
  if rule3 is not None:
    if rule1 not in eca_images:
      eca_images[rule1] = {}
    if rule2 not in eca_images[rule1]:
      eca_images[rule1][rule2] = {}
    eca_images[rule1][rule2][rule3] = ca

  elif rule2 is not None:
    if rule1 not in eca_images:
      eca_images[rule1] = {}
    eca_images[rule1][rule2] = ca

  else:
    eca_images[rule1] = ca

print(f'min_rule1 max_rule1 : {min_rule1} {max_rule1}')
print(f'min_rule2 max_rule2 : {min_rule2} {max_rule2}')
print(f'min_rule3 max_rule3 : {min_rule3} {max_rule3}')

print(min_rule1, max_rule1, min_rule2, max_rule2, max_rule3, max_rule3)

"""#### Visual Inspection"""

import pprint

image = eca_images[131]
# Print nested structure

pprint.pprint(image)

# Log contents at each level
# print("Level 1:", eca_images[106])
# print("Level 2:", eca_images[106][54])
# print("Level 3:", eca_images[106][54][54])
# print("Level 4:", eca_images)

# Check type of each level
# print(type(eca_images[106]))
# print(type(eca_images[106][54]))

# Check the type to know how to plot it
# print(type(eca_images[106][54][54]))

# For example, if it's a numpy array:
import matplotlib.pyplot as plt
plt.imshow(image)
plt.show()

image_array = eca_images[41][0][0]
image_array.shape

import matplotlib.pyplot as plt

fig, ax = plt.subplots(figsize=(10,10))
ax.imshow(image_array)
plt.show()

"""### Visualisation"""

# Shows the 8 selected stocks and their corresponding sectors/industries
stocks = ['AAPL', 'BA', 'CAT', 'DIS', 'GE', 'IBM', 'MSFT', 'TSLA']
sectors = ['Technology', 'Industrials', 'Industrials', 'Communication Services',
           'Industrials', 'Technology', 'Technology', 'Consumer Discretionary']
industries = ['Consumer Electronics', 'Aerospace & Defense', 'Machinery', 'Entertainment',
              'Diversified Industrials','IT Consulting & Services', 'Software', 'Automotive']

md_table = '| Stock | Sector | Industry |\n|-|-|-\n'

for stock, sector, industry in zip(stocks, sectors, industries):
    md_table += f'| {stock} | {sector} | {industry} |\n'

print(md_table)

"""| Stock | Sector | Industry |
|-|-|-
| AAPL | Technology | Consumer Electronics |
| BA | Industrials | Aerospace & Defense |
| CAT | Industrials | Machinery |
| DIS | Communication Services | Entertainment |
| GE | Industrials | Diversified Industrials |
| IBM | Technology | IT Consulting & Services |
| MSFT | Technology | Software |
| TSLA | Consumer Discretionary | Automotive |
"""

# Shows the respective last closing prices of the 8 selected stocks
import matplotlib.pyplot as plt

tickers = ['AAPL', 'BA', 'CAT', 'DIS', 'GE', 'IBM', 'MSFT', 'TSLA']

# Get last row to plot bar heights
prices = data[tickers].iloc[-1].to_numpy()

# Plot bar chart
plt.bar(tickers, prices)
plt.xlabel('Stocks')
plt.ylabel('Price ($)')
plt.title('Selected Stocks')

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Extract a subset of rows
subset = observed_data_arr[:20, :]

# Plot binary string values
fig, ax = plt.subplots()
im = ax.imshow(subset, cmap='binary')

# Show all ticks and label them
ax.set_xticks(np.arange(len(subset[0])))
ax.set_yticks(np.arange(len(subset)))
ax.set_xticklabels([f'Bit {i+1}' for i in range(len(subset[0]))])
ax.set_yticklabels([f'Day {i+1}' for i in range(len(subset))])

# Rotate the tick labels and set their alignment.
plt.setp(ax.get_xticklabels(), rotation=45, ha="right",
         rotation_mode="anchor")

# Add colorbar
fig.colorbar(im, ax=ax)
plt.title("Encoded 32-bit Binary Strings")
plt.tight_layout()
plt.show()

""""Figure X below shows a heatmap visualization of the encoded stock price change data over the first 5 days of the 192 day study period. Each row represents one day, and each column corresponds to one of the 8 selected stocks. The color scale indicates the percentage change in closing price for each stock on each day after encoding into a 32-bit binary string. Red shades map to positive increases, blue shades indicate decreases, and white signifies little to no change.
The color bar provides a key for interpreting the visualization, with the colored bins representing ranges of percent change from 0-2% up through >20%. This reveals the distribution of price changes and makes it possible to quickly identify days or stocks with significant positive or negative shifts.
For example, on Day 1 Apple and Microsoft saw minor positive changes in the 2-4% range in red, while Boeing and Disney declined 4-8% in blue. Overall the plot provides a succinct overview of the encoded data and how the stocks moved over this initial sample period."

"""

import matplotlib as mpl
import matplotlib.pyplot as plt

# Create bins and labels
bins = [0.02, 0.04, 0.08, 0.12, 0.16, 0.20, 0.24, 1]
labels = ['0-2%', '2-4%', '4-8%', '8-12%', '12-16%', '16-20%', '20-24%', '>24%']

# Set color map
cmap = mpl.colormaps['Set1'](len(labels))

# fig = plt.figure(figsize=(10,10))  # larger figure size
# ax = fig.add_axes([0, 0, 1, 1]) # make axes fill figure
# Create figure and axes
fig, ax = plt.subplots(figsize=(10, 8))
ax.set_position([0, 0, 1, 1])

# Plot with binned color bar
im = ax.imshow(observed_data_arr)

# Set color bar labels
cb = fig.colorbar(im, cax=ax, ticks=bins, orientation='horizontal')
cb.set_ticklabels(labels)

cb.set_label('Percent Change', size=12)
# Set colorbar width to match image axes
cb.ax.set_position([0, 0, 1, 0.08])

plt.title("Encoded 32-bit Binary Strings")
# plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec

# def int_to_magnitude(val):
#   if val <= 2: return 0.1
#   elif val <= 3: return 0.3
#   elif val <= 4: return 0.4
#   elif val <= 5: return 0.5
#   elif val <= 6: return 0.6
#   elif val <= 7: return 0.8
#   else: return 1.0

def bits_to_mag(bits):
  if   bits == '000': return 2
  elif bits == '001': return 4
  elif bits == '010': return 8
  elif bits == '011': return 12
  elif bits == '100': return 16
  elif bits == '101': return 20
  elif bits == '110': return 24
  elif bits == '111': return 100

input_image = observed_data_arr

# Extract sign bits
signs = observed_data_arr[:,0::4]

# Extract 3-bit magnitude codes
aapl_code = input_image[:,1:4]
ba_code = input_image[:,5:8]
cat_code = input_image[:,9:12]
dis_code = input_image[:,13:16]
ge_code = input_image[:,17:20]
ibm_code = input_image[:,21:24]
msft_code = input_image[:,25:28]
tsla_code = input_image[:,29:32]

# Convert to integer arrays
aapl_ints = aapl_code.astype(int)
ba_ints = aapl_code.astype(int)
cat_ints = aapl_code.astype(int)
dis_ints = aapl_code.astype(int)
ge_ints = aapl_code.astype(int)
ibm_ints = aapl_code.astype(int)
msft_ints = aapl_code.astype(int)
tsla_ints = aapl_code.astype(int)

# Map integers to magnitudes
aapl_mags = np.vectorize(bits_to_mag)(aapl_ints)
ba_mags = np.vectorize(bits_to_mag)(ba_ints)
cat_mags = np.vectorize(bits_to_mag)(cat_ints)
dis_mags = np.vectorize(bits_to_mag)(dis_ints)
ge_mags = np.vectorize(bits_to_mag)(ge_ints)
ibm_mags = np.vectorize(bits_to_mag)(ibm_ints)
msft_mags = np.vectorize(bits_to_mag)(msft_ints)
tsla_mags = np.vectorize(bits_to_mag)(tsla_ints)

# Stack magnitude bits
image = np.dstack([aapl_mags, ba_mags, cat_mags, dis_mags,
                   ge_mags, ibm_mags, msft_mags, tsla_mags])

# Flatten to make 2D
image = image.reshape(image.shape[0], -1)

# Normalize to 0-1
# aapl_norm = aapl_mags / 1.0

# Concatenate sign bits and image
recreated = np.concatenate((signs, image), axis=1)

# Create figure
fig = plt.figure(figsize=(10,8))

# Calculate ratio of axes heights
img_height = 0.8
cb_height = 0.2
height_ratio = [img_height, cb_height]

# Create GridSpec with height ratios
gs = gridspec.GridSpec(nrows=1, ncols=3, height_ratios=[1])

# Create axes for image
ax1 = fig.add_subplot(gs[0,0])
ax2 = fig.add_subplot(gs[0,1])

# Create axes for colorbar
cbar_ax = fig.add_subplot(gs[:,2])
cbar_ax.set_aspect(40)

# Plot original on ax1
ax1.imshow(observed_data_arr, cmap='gray')

# Plot recreated on ax2
ax2.imshow(recreated)

# Set colormap
im.set_cmap('RdYlGn_r')

# Create colorbar
cb = fig.colorbar(im, cax=cbar_ax, orientation='vertical')


# Set labels, ticks, etc.
# Set tick labels
# cb.set_ticks([0, 0.25, 0.5, 0.75, 1])
# cb.set_ticklabels(['0-2%','4-8%','8-16%','16-24%','>24%'])
cb.set_ticks([2,4,8,12,16,20,24,100])
cb.set_ticklabels(['0-2%','2-4%','4-8%','8-12%', '12-16%', '16-20%', '20-24%', '>24%'])
im.set_clim(0, 24)
# Show plot
plt.show()

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Load in encoded observed data
input_image = observed_data_arr

# Get list of dates
dates = df_cleaned.index.date.tolist()

# Get list of stock tickers
tickers = ['AAPL', 'BA', 'CAT', 'DIS', 'GE', 'IBM', 'MSFT', 'TSLA']

# Extract just the 3-bit magnitude portions
mags = input_image[:,1::4]

# Map magnitude bits to color scale
cmap = plt.cm.get_cmap('RdYlGn', 8)
cmap_mags = cmap(np.arange(8))

# Initialize mapped magnitude array
mapped_mags = np.empty_like(mags, dtype='object')

# Map bits to colors
for i in range(8):
  idx = mags == i
  mapped_mags[idx] = cmap_mags[i]

# Plot heatmap
fig, ax = plt.subplots(figsize=(12,8))
im = ax.imshow(mapped_mags, interpolation='spline16')

# Colorbar
cbar = fig.colorbar(im, ticks=np.arange(8))
cbar.ax.set_yticklabels(['0-2%', '2-4%', '4-8%', '8-12%', '12-16%', '16-20%', '20-24%', '>24%'])

# Labels and titles
plt.xlabel('Stock Ticker')
plt.yticks(np.arange(len(dates)), dates)
plt.title('Encoded Magnitude Heatmap')

plt.show()

import numpy as np
import matplotlib.pyplot as plt

input_image = observed_data_arr

# Sign mapping
def map_signs(signs):
  sign_colors = [-1, 0, 1]
  return np.digitize(signs, sign_colors)

# Magnitude mapping
def map_mags(mags):
  mag_cmap = plt.cm.get_cmap('RdBu', 8)
  return mag_cmap(mags)

# Combine mappings
def apply_cmap(sign_map, mag_map):

  # Flatten to match sign_map shape
  mag_map_flat = mag_map.reshape(192, -1)

  intensity_weights = np.array([0.2989, 0.5870, 0.1140])

  intensity = np.dot(mag_map_flat, intensity_weights)

  return intensity[sign_map]


# Initialize encoded image array
encoded_img = np.empty_like(input_image)

# Loop through stocks
for i in range(8):

  # Get sign and mag bits
  signs = input_image[:, 4*i]
  mags = input_image[:, 4*i+1 : 4*i+4]

  # Map sign and mag
  sign_map = map_signs(signs)
  mag_map = map_mags(mags)

  # Combine mappings
  full_map = apply_cmap(sign_map, mag_map)

  # Insert into image array
  encoded_img[:, 4*i:4*i+4] = full_map

# Plot the image
plt.imshow(encoded_img)
plt.xticks(np.arange(8), tickers)
plt.yticks(np.arange(192), np.arange(1,193))
plt.colorbar()
plt.title('Encoded Heatmap')

plt.show()

# Map mags to (192, 4)
def map_mags(mags):

  mags_flat = mags.reshape(-1)

  repeated = np.repeat(mags_flat/7, 1)

  return repeated.reshape(192, 3)

# Apply signs to (192, 4) intensity
def apply_cmap(signs, intensity):
  signs = signs.reshape(-1, 1)
  return signs * intensity

# Loop through stocks
for i in range(8):

  signs = input_image[:, 4*i]
  mags = input_image[:, 4*i+1:4*i+4]

  intensity = map_mags(mags) # (192, 4)
  signed_int = apply_cmap(signs, intensity) # (192, 4)

  encoded_img[:, 4*i:4*i+4] = signed_int # Insert into (192, 32)

"""## 2. Elementary Cellular Automata (ECA)
* An ECA is used to generate 2D arrays of binary values  using rules composition as described in https://arxiv.org/abs/1802.08769
* We use the first encoded price change data as the initial cells configuration of an ECA to begin the process of evolving the initial cell state for the next 192 steps or iterations by applying one or more of a set of 256 rules encoded using 8 bits on the initial row of cells.  We name all these generated 2D binary arrays as Gs for generated market data.  Rules can be composed as defined in https://arxiv.org/abs/1802.08769. We allow maximum of 3 rules in any composition.  Thus, rules are encoded in a 8 bit x 3 long binary sequence, named ECA_Rule.
- Reference: https://cellpylib.org and https://arxiv.org/abs/1802.08769
"""

pip install cellpylib

# pip install git+https://github.com/lantunes/cellpylib.git

"""### Custom ECA Image Generation"""

eca_input_string = '01110111011101110111011101110111'

"""#### Perform a quick visual test

Use any of one of the following 88 essential rules for better effect
* 8 Class 1 ECA rules (0, 8, 32, 40, 128, 136, 160, 168)
* 65 Class 2 ECA rules (1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 19, 23,
24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 37, 38, 42, 43, 44, 46, 50, 51, 56, 57,
58, 62, 72, 73, 74, 76, 77, 78, 94, 104, 108, 130, 132, 134, 138, 140, 142,
152, 154, 156, 162, 164, 170, 172, 178, 184, 200, 204, 232)
* 11 Class 3 ECA rules (18, 22, 30, 45, 60, 90, 105, 122, 126, 146, 150)
* 4 class 4 rules (41, 54, 106, 110)

"""

import numpy as np
import cellpylib as cpl
import pickle

# Get list of all 256 possible ECA rules
all_eca_rules = [
     0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,
     16, 17, 18, 19, 20, 21, 22 ,23, 24, 25, 26, 27, 28, 29, 30, 31,
     32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,
     48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,
     64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79,
     80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95,
     96, 97, 98, 99, 100,101,102,103,104,105,106,107,108,109,110,111,
     112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,
     128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,
     144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,
     160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,
     176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,
     192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,
     208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,
     224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,
     240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255
]

# Convert input data to list of integers
int_list = [int(bit) for bit in eca_input_string]

# Dictionary to store images
eca_images = {}
rule1 = 106
rule2 = 54
rule3 = 54
def triple_rules(rule1, rule2, rule3):
    def composed_rule(n, c, t):
        # Apply rule 1
        c1 = cpl.nks_rule(n, rule1)
        # Apply rule 2
        c2 = cpl.nks_rule(n, rule2)
        # Apply rule 3
        c3 = cpl.nks_rule(n, rule3)
        return c1*c2*c3
    return composed_rule
ca3 = cpl.evolve(np.array([int_list], dtype=int), timesteps=TOTAL_LEN,
                apply_rule=triple_rules(rule1, rule2, rule3))
cpl.plot(ca3)

ca = cpl.evolve(np.array([int_list], dtype=int), timesteps=TOTAL_LEN,
                apply_rule=lambda n, c, t: cpl.nks_rule(n,rule1))
cpl.plot(ca)

# Save evolved CA
with open(f'eca_images{rule1}_{rule2}_{rule3}.pkl', 'wb') as f:
  pickle.dump(ca3, f)

"""#### Single Rule Generation"""

import numpy as np
import cellpylib as cpl
import pickle

# Get list of all 256 possible ECA rules
all_eca_rules = [
     0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,
     16, 17, 18, 19, 20, 21, 22 ,23, 24, 25, 26, 27, 28, 29, 30, 31,
     32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,
     48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,
     64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79,
     80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95,
     96, 97, 98, 99, 100,101,102,103,104,105,106,107,108,109,110,111,
     112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,
     128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,
     144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,
     160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,
     176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,
     192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,
     208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,
     224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,
     240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255
]

# Convert input data to list of integers
int_list = [int(bit) for bit in eca_input_string]

# Dictionary to store images
eca_images = {}
rule1 = 0
rule2 = 0
rule3 = 0

# Single Rule Generation
# Iterate over each individual ECA rule
# for rule1 in all_eca_rules:
for rule1 in range(0, len(all_eca_rules)):

    # Evolve CA with rule1
    ca1 = cpl.evolve(np.array([int_list], dtype=int), timesteps=TOTAL_LEN,
                     apply_rule=lambda n, c, t: cpl.nks_rule(n, rule1))

    # Save evolved CA
    with open(f'eca_images{rule1}.pkl', 'wb') as f:
        pickle.dump(ca1, f)

"""#### Double Rule Generation"""

import numpy as np
import cellpylib as cpl
import pickle

# Get list of all 256 possible ECA rules
all_eca_rules = [
     0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,
     16, 17, 18, 19, 20, 21, 22 ,23, 24, 25, 26, 27, 28, 29, 30, 31,
     32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,
     48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,
     64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79,
     80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95,
     96, 97, 98, 99, 100,101,102,103,104,105,106,107,108,109,110,111,
     112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,
     128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,
     144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,
     160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,
     176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,
     192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,
     208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,
     224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,
     240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255
]

# Convert input data to list of integers
int_list = [int(bit) for bit in eca_input_string]

# Dictionary to store images
eca_images = {}
rule1 = 0
rule2 = 0
rule3 = 0

def double_rules(rule1, rule2):
    def composed_rule(n, c, t):
        # Apply rule 1
        c1 = cpl.nks_rule(n, rule1)
        # Apply rule 2
        c2 = cpl.nks_rule(n, rule2)
        return c1*c2
    return composed_rule


# Double Rule Generation
# Iterate over each individual ECA rule
# for rule1 in all_eca_rules:
for rule1 in range(0, len(all_eca_rules)):

  # Iterate over each pair of ECA rules
  # for rule2 in all_eca_rules:
  for rule2 in range(0, len(all_eca_rules)):

    ca2 = cpl.evolve(np.array([int_list], dtype=int), timesteps=TOTAL_LEN,
                    apply_rule=double_rules(rule1, rule2))

    # Save evolved CA
    with open(f'eca_images{rule1}_{rule2}.pkl', 'wb') as f:
        pickle.dump(ca2, f)

"""#### Triple Rule Generation"""

import numpy as np
import cellpylib as cpl
import pickle

# Get list of all 256 possible ECA rules
all_eca_rules = [
     0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,
     16, 17, 18, 19, 20, 21, 22 ,23, 24, 25, 26, 27, 28, 29, 30, 31,
     32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,
     48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,
     64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79,
     80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95,
     96, 97, 98, 99, 100,101,102,103,104,105,106,107,108,109,110,111,
     112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,
     128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,
     144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,
     160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,
     176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,
     192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,
     208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,
     224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,
     240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255
]

# Convert input data to list of integers
int_list = [int(bit) for bit in eca_input_string]

# Dictionary to store images
eca_images = {}
rule1 = 54
rule2 = 54
rule3 = 54

def triple_rules(rule1, rule2, rule3):
    def composed_rule(n, c, t):
        # Apply rule 1
        c1 = cpl.nks_rule(n, rule1)
        # Apply rule 2
        c2 = cpl.nks_rule(n, rule2)
        # Apply rule 3
        c3 = cpl.nks_rule(n, rule3)
        return c1*c2*c3
    return composed_rule


# Double Rule Generation
# Iterate over each individual ECA rule
# for rule1 in all_eca_rules:
for rule1 in range(0, len(all_eca_rules)):

  # Iterate over each pair of ECA rules
  # for rule2 in all_eca_rules:
  for rule2 in range(0, len(all_eca_rules)):

    # Iterate over each trio of ECA rules
    for rule3 in range(0, len(all_eca_rules)):
    # for rule3 in all_eca_rules:

      ca3 = cpl.evolve(np.array([int_list], dtype=int), timesteps=TOTAL_LEN,
                    apply_rule=triple_rules(rule1, rule2, rule3))

      # Save evolved CA
      with open(f'eca_images{rule1}_{rule2}_{rule3}.pkl', 'wb') as f:
        pickle.dump(ca3, f)

"""### Unzip and load 2D arrays"""

cd /content/drive/MyDrive/Colab Notebooks/eca_images_1r

import os
import zipfile
import time

def get_subfolder(parent_folder, count):

  subfolder_name = f"subfolder-{count}"
  subfolder_path = os.path.join(parent_folder, subfolder_name)

  return subfolder_path

def create_subfolder(parent_folder, count):

  subfolder_name = f"subfolder-{count}"
  subfolder_path = os.path.join(parent_folder, subfolder_name)

  os.makedirs(subfolder_path)

  return subfolder_path

def unzip_files(zip_file, output_folder):

  folder = {}
  file_count = 0
  subfolder_count = 0
  folder_stats = []
  extract_to = output_folder

  with zipfile.ZipFile(zip_file) as zf:

    for filename in zf.namelist():

      if file_count % 5000 == 0:

        subfolder = get_subfolder(output_folder, subfolder_count)
        extract_to = subfolder

        print(f"Processing Folder : {extract_to} subfolder count : {subfolder_count} file count : {file_count}")

        if os.path.exists(extract_to):
          subfolder_count += 1
        else:
          subfolder = create_subfolder(output_folder, subfolder_count)
          subfolder_count += 1

        folder = {
          'folder': subfolder,
          'file_count': 0
        }
        folder_stats.append(folder)

      extract_path = os.path.join(extract_to, filename)
      if os.path.exists(extract_path):
        file_count += 1
        folder['file_count'] += 1
        continue # skip extracting file

      zf.extract(filename, extract_to)
      file_count += 1
      folder['file_count'] += 1

      if file_count % 100 == 0:
        time.sleep(120) # delay 2 minute

  # Calculate totals
  total_files = sum(f['file_count'] for f in folder_stats)
  num_folders = len(folder_stats)

  print(f"Folders: {num_folders}")
  print(f"Total files: {total_files}")

  return folder_stats

# Usage
# zip_file = ...
# output_path = ...

# unzip_files(zip_file, output_path)

import matplotlib.pyplot as plt
plt.imshow(eca_images[])
plt.show()

"""### Visualisation"""

import matplotlib.pyplot as plt

# Initial row
init_row = [0, 1, 0, 1, 0, 1, 0, 1]

# Sample rule 90
rule = 90

# Compute next row
next_row = []
for i in range(len(init_row)):
    left = init_row[i-1] if i > 0 else 0
    me = init_row[i]
    right = init_row[(i+1)%len(init_row)]
    triplet = (left, me, right)
    if triplet == (1,1,1):
        next_row.append(0) if rule >= 128 else next_row.append(1)
    elif triplet == (1,1,0):
        next_row.append(0) if 64 <= rule < 128 else next_row.append(1)
    elif triplet == (1,0,1):
        next_row.append(0) if 32 <= rule < 64 else next_row.append(1)
    elif triplet == (1,0,0):
        next_row.append(0) if 16 <= rule < 32 else next_row.append(1)
    elif triplet == (0,1,1):
        next_row.append(0) if 8 <= rule < 16 else next_row.append(1)
    elif triplet == (0,1,0):
        next_row.append(0) if 4 <= rule < 8 else next_row.append(1)
    elif triplet == (0,0,1):
        next_row.append(0) if 2 <= rule < 4 else next_row.append(1)
    else:
        next_row.append(0) if rule < 2 else next_row.append(1)

# Plot
fig, axs = plt.subplots(1, 2, figsize=(6,2))
axs[0].set_title('Initial Row')
axs[0].set_ylim(-0.5, 1.5)
axs[0].plot(init_row, 'ok')

axs[1].set_title('Next Row (Rule 90)')
axs[1].set_ylim(-0.5, 1.5)
axs[1].plot(next_row, 'ok')

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Generate ECA patterns
def generate_eca(init, rules, steps):

    pattern = np.zeros((steps+1, len(init)), dtype=int)
    pattern[0] = init

    for i in range(steps):

        # Apply rule 1
        row1 = generate_row(pattern[i], rules[0])

        # Apply rule 2
        row2 = generate_row(pattern[i], rules[1])

        # Multiply the rows
        next_row = np.multiply(row1, row2)

        pattern[i+1] = next_row

    return pattern


def generate_row(prev_row, rule):

  next_row = []

  for j in range(len(prev_row)):

    left = prev_row[j-1] if j>0 else 0
    me = prev_row[j]
    right = prev_row[(j+1)%len(prev_row)]

    next_cell = rule_lookup((left, me, right), rule)

    next_row.append(next_cell)

  return np.array(next_row)

# Rule lookup table
def rule_lookup(triplet, rule):

    if triplet == (1,1,1):
        return 0 if rule >= 128 else 1
    elif triplet == (1,1,0):
        return 0 if 64 <= rule < 128 else 1
    elif triplet == (1,0,1):
        return 0 if 32 <= rule < 64 else 1
    elif triplet == (1,0,0):
        return 0 if 16 <= rule < 32 else 1
    elif triplet == (0,1,1):
        return 0 if 8 <= rule < 16 else 1
    elif triplet == (0,1,0):
        return 0 if 4 <= rule < 8 else 1
    elif triplet == (0,0,1):
        return 0 if 2 <= rule < 4 else 1
    else:
        return 0 if rule < 2 else 1

# Generate single rule pattern
init1 = [0,1,0,1,0,1,0,1]
pattern1 = generate_eca(init1, [90], 5)

# Convert to NumPy array
pattern1_arr = np.array(pattern1)

# Generate double rule pattern
init2 = [0,1,1,0,1,0,1,0]
pattern2 = generate_eca(init2, [90, 150], 5)

# Convert to NumPy array
pattern2_arr = np.array(pattern2)

# Plot patterns
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))

ax1.set_title('Rule 90')
ax1.imshow(pattern1_arr)

ax2.set_title('Rule 90 + 150')
ax2.imshow(pattern2_arr)

plt.tight_layout()
plt.show()

"""## 3. Minimal Algorithmic Information Loss Methods (MILS)

* Block Decompoisition Method (BDM)
 * This Github repository <https://github.com/sztal/pybdm> implements the BDM as defined in https://pybdm-docs.readthedocs.io/en/latest/theory.html
 * It is used by MILS described below to estimate the algorithmic complexity aka information content of a given 2D binary array
 * Reference:
    * https://github.com/sztal/pybdm
    * https://pybdm-docs.readthedocs.io/en/latest/theory.html


* MILS algorithm implements dimensional reduction and feature selection to minimise information loss and preserve maximal information on a given 2D binary array as described in https://arxiv.org/abs/1802.05843
* It first evaluate the potential information loss due to a row or column of the given 2D array.
* It then sort them in a list of candidate rows/cols to be deleted
* Finally, it proceeds to delete rows/cols starting with the first identified in the above sorted list of indices
* This Github repository <https://github.com/sztal/pybdm> implements MILS - based on theory https://pybdm-docs.readthedocs.io/en/latest/theory.html to estimate the algorithmic complexity of an input square 2D array of binary values
* Reference:
  * https://github.com/alyssa-adams/pymils
  * https://arxiv.org/abs/1802.05843
"""

pip install git+https://github.com/sztal/pybdm.git

# Defined Constants
MIN_SIZE = 0.5 # 0-1 fraction of image size

"""### PyMILS"""

from typing import Tuple
import random
import numpy as np
from pybdm import BDM


class PyMILS():
  """Perform the MILS compression algorithm."""

  def __init__(self, bdm_tool: BDM, min_size: float) -> None:
    self.bdm_tool = bdm_tool
    self.min_size = min_size
    self.loss_cache = {}

  def init_mils(self, img):
    """Initialize MILS algorithm.

    Calculates initial BDM, minimum dimensions, and number of
    row/column deletions needed.

    Args:
      img: Input image as NumPy array

    Returns:
      Tuple of (initial BDM, minimum rows, minimum cols,
               row deletions needed, col deletions needed)
    """

    initial_bdm = self.calculate_bdm(img)

    # Minimum size thresholds
    min_rows = int(self.min_size * img.shape[0])
    min_cols = int(self.min_size * img.shape[1])

    # Calculate number of row/col deletions needed
    row_dels = img.shape[0] - min_rows
    col_dels = img.shape[1] - min_cols

    return initial_bdm, min_rows, min_cols, row_dels, col_dels

  def calculate_bdm(self, img: np.ndarray) -> float:
    """Calculate the BDM complexity of an image."""

    try:
      bdm = self.bdm_tool.bdm(img)
    except Exception as e:
      raise ValueError("Error computing BDM") from e
    if bdm == 0:
      print('Computed BSM = 0')
    return bdm

  def sample_index(self, n: int) -> int:
    """
    Sample a random valid index to perturb.

    Args:
      n: Size of dimension

    Returns:
      Random row or column index
    """
    return random.choice(range(n))

  def get_stock_cols(self, col_idx):
    start_col = col_idx - col_idx % 4 # Each stock is encoded with 4 bits
    return range(start_col, start_col+4)

  def get_stock_idx(self, col_idx):
    return col_idx // 4 # Each stock is encoded with 4 bits

  def evaluate_loss(self, img: np.ndarray, index: int) -> float:
    """
    Evaluate information loss from row/col deletion.

    Args:
      img: Input image
      index: Row or column index to delete

    Returns:
      Information loss from deleting index
    """
    stock_idx = self.get_stock_idx(index-img.shape[0])

    if stock_idx in self.loss_cache:
      # Hit cache
      return self.loss_cache[stock_idx]

    perturbed = self.delete(img, index)
    original_bdm = self.calculate_bdm(img)
    perturbed_bdm = self.calculate_bdm(perturbed)
    loss = abs(original_bdm - perturbed_bdm)

    # Cache result
    self.loss_cache[stock_idx] = loss

    return loss


  def delete(self, img: np.ndarray, index: int) -> np.ndarray:
    """
    Delete a row or column.

    Args:
      img: Input image
      index: Row or column index to delete

    Returns:
      Perturbed image
    """
    if index < 0 or index >= img.shape[0] + img.shape[1]:
      raise ValueError("Index out of bounds")

    # Delete row
    if index < img.shape[0]:
      return np.delete(img, index, axis=0)

    # Delete column
    else:
      cols = self.get_stock_cols(index-img.shape[0])
      return np.delete(img, cols, axis=1)

  def zero_out(self, img: np.ndarray, index: int) -> np.ndarray:

    if index < img.shape[0]:
      img[index,:] = 0

    else:
      cols = self.get_stock_cols(index-img.shape[0])
      img[:, cols] = 0

    return img


  def meets_size_criteria(self, img, current_idx, min_size) -> bool:
    print(f'current_idx : {current_idx} min_size : {min_size}')

    if current_idx < img.shape[0]:
      # Row index, check rows
      current_size = img.shape[0]
      min_size = int(min_size * current_size)
      print(f'row min_size : {min_size}')
      return current_size > min_size

    else:
      # Col index, check cols
      current_size = img.shape[1]
      min_size = int(min_size * current_size)
      print(f'col min_size : {min_size}')
      return current_size > min_size

  def check_size_criteria(self, img, sorted_indices, sorted_losses, min_size):

    allowed_row_dels = int(img.shape[0] * (1 - min_size))
    allowed_col_dels = int(img.shape[1] * (1 - min_size))

    index_loss_pairs = zip(sorted_indices, sorted_losses)

    qualified_indices = []
    qualified_losses = []

    for i, loss in index_loss_pairs:

      if i < img.shape[0]:
        # Row deletion
        if len(qualified_indices) >= allowed_row_dels:
          break

        qualified_indices.append(i)
        qualified_losses.append(loss)

      else:
        # Col deletion
        if len(qualified_indices) >= allowed_col_dels:
          break

        qualified_indices.append(i)
        qualified_losses.append(loss)

    print(f'len qualified_indices : {len(qualified_indices)}')

    return qualified_indices, qualified_losses

  def mils(self, image, sorted_indices, sorted_losses):
    """
    Integrated MILS implementation using genetic algorithm.
    """

    # Set minimum image size
    min_size = MIN_SIZE

    current_complexity = self.calculate_bdm(image)
    # Set minimum complexity threshold
    relative_threshold = 0.5
    min_complexity = relative_threshold * current_complexity

    # Set minimum delta complexity to determine if it has stabilized
    min_delta = 0.001

    # Set maximum allowed complexity loss
    max_allowed_loss = 0.5 * current_complexity

    img = image
    prev_complexity = current_complexity

    qualfied_indices, qualified_losses = self.check_size_criteria(image, sorted_indices, sorted_losses, min_size)
    print(f'qualified_indices : {qualfied_indices} qualified_losses : {qualified_losses} ')

    # Delete using by list of sorted losses
    for loss, i in zip(qualified_losses, qualfied_indices):

      img = self.zero_out(img, i)  # delete will change the shape of the image

      # Check complexity
      complexity = self.calculate_bdm(img) # image is distorted with zeros
      # since we are comparing complexity within different configurations of itself

      if complexity < min_complexity:
        print(f'Complexity threshold exceeded!')
        break

      # Check delta complexity
      delta = abs(complexity - prev_complexity)
      if delta < min_delta:
        print(f'Delta threshold exceeded!')
        break

      # Check info loss
      if loss > max_allowed_loss:
        print(f'Max Allowed Loss threshold exceeded!')
        break

      # Check min size limit
      # print(f'Checking min size using index {i}')
      # if self.meets_size_criteria(img, i, min_size):
      #   print(f'Size threshold exceeded at index {i}!')
      #   break

      prev_complexity = complexity

    #* Use np.delete() to delete rows/cols that were filled with zeros above
    # Delete rows/cols from original image
    # print(f'img.shape : {img.shape}')
    # print(f'image.shape : {image.shape}')

    row_indices = []
    col_indices = []

    for index_value in sorted_indices:

      if index_value < image.shape[0]:
        row_indices.append(index_value)
      else:
        # col_indices.append(index_value - image.shape[0])
        cols = self.get_stock_cols(index_value-img.shape[0])
        col_indices.extend(cols)

    # print(f'row_indices : {row_indices}')
    # print(f'col_indices : {col_indices}')
    print(f'len row_indices : {len(row_indices)}')
    print(f'len col_indices : {len(col_indices)}')

    compressed_image = np.delete(img, row_indices, axis=0)
    compressed_image = np.delete(compressed_image, col_indices, axis=1)
    #* Use np.delete() to delete rows/cols that were filled with zeros above

    return compressed_image

"""## 5. Evotorch Genetic Algorithm (EGA)
* This Github repository https://github.com/nnaisense/evotorch implements a genetic algorithm that is used for 2 purposes in this project
  * Firstly, to perform row/col selection of an input 2D array of binary values using EGA by minimising the total information loss of each row/col if each is deleted from the original image.
  * Secondly, to perform eca_rule selection (single, double or triple rule composition) using EGA by minimising the information distance between a target image and generated image using a candidate eca_rule.
* Reference:
  * https://github.com/nnaisense/evotorch
"""

pip install evotorch

"""### RowColSelection Problem"""

from evotorch import Problem, Solution

# Define problem
class RowColSelection(Problem):

  def __init__(self, image, pymils,
               objective_sense,
               dtype,
               initial_bounds):

    self.input_image = image
    self.pymils = pymils
    solution_length = image.shape[0] + image.shape[1]

    super().__init__(
      objective_sense,
      solution_length=solution_length,
      dtype=dtype,
      initial_bounds=initial_bounds
    )

  def _evaluate(self, solution: Solution):
    evals = objective_rcs(solution, self.input_image, self.pymils)
    solution.set_evals(evals)

# Row/Col Selection fitness function
def objective_rcs(solutions, image, pymils):
  """
  Objective function to evaluate fitness of a mask Solution.
  """

  # Convert mask to boolean tensor
  #mask = Solution(mask).values.bool()
  # print(f'inside objective: mask is {mask}')

  losses = []

  for i, bit in enumerate(solutions):
    if bit:
        # Delete row/col
        # img = self.pymils.delete(self.input_image, i)

        # Get information loss
        loss = pymils.evaluate_loss(image, i)

        losses.append(loss)

  # print(f"Losses : {sum(losses)}")

  return sum(losses)

"""### GA Operators"""

from evotorch.operators import Operator
from evotorch.operators import CrossOver

# Define binary mutation operator
class BinaryMutation(Operator):

  def __init__(self, problem, mutation_prob):
    self.mutation_prob = mutation_prob
    super().__init__(problem)

  def _do(self, solutions):

    sln_values = solutions.access_values()
    #print("Solution bits:", *sln_values)

    for i in range(sln_values.shape[0]):

      if random.random() < self.mutation_prob:

        # Randomly select a bit position to flip
        pos = torch.randint(0, sln_values.shape[1], (1,))

        # print(f"Mutating population of shape: {solutions.values_shape}")
        # print(f"Before mutation: {sln_values}")

        # Save pre-mutation version
        pre_mutation = sln_values[i].clone()

        # Flip the bit
        sln_values[i, pos] = 1 - sln_values[i, pos]

        # print(f"After mutation: {sln_values}")
        # print(f"Mutation position: {pos}")

        # Count mutated bits
        num_mutated = (sln_values[i] != pre_mutation).sum()
        print(f"Num mutated: {num_mutated}")

    return

# Define binary crossover operator
class BinaryCrossOver(CrossOver):

  def __init__(self, problem, tournament_size):
    super().__init__(problem, tournament_size=tournament_size)

  def _do_cross_over(self, parents1, parents2):
    # a parent tensor consists of [number of parents, solution_length]

    num_parents_pairs = len(parents1)
    solution_length = self._problem._solution_length

    assert len(parents1) == len(parents2)

    children = SolutionBatch(self._problem, popsize=num_parents_pairs*2, empty=True)
    children_values = children.access_values()

    num_crossed_total = 0

    for i in range(num_parents_pairs):

      p1 = parents1[i]
      p2 = parents2[i]

      ### single crossover point
      # crossover_point = random.randint(0, solution_length-1)

      # child1 = torch.cat((p1[:crossover_point], p2[crossover_point:]))
      # child2 = torch.cat((p2[:crossover_point], p1[crossover_point:]))
      ###

      # Generate uniform crossover mask
      mask = torch.bernoulli(0.5 * torch.ones(solution_length))

      # Apply mask to create children
      child1 = torch.where(mask==1, p1, p2)
      child2 = torch.where(mask==0, p1, p2)

      children_values[i] = child1
      children_values[i+num_parents_pairs] = child2

      # Track bits crossed
      # crossover_bits = p1[crossover_point:]
      # num_crossed = len(set(crossover_bits))
      # num_crossed_total += num_crossed

      # Crossover rate = mean of mask values
      crossover_rate = mask.float().mean()

      print(f"Crossover rate: {crossover_rate:.2%}")

    # print(f"Total bits crossed: {num_crossed_total}")

    return children

"""### Compress 2D array"""

import torch
from evotorch import Problem, Solution, SolutionBatch
from evotorch.algorithms import GeneticAlgorithm
from evotorch.operators import Operator
from evotorch.operators import CrossOver
import random

# PyMILS class definition...

# RowColSelection class definition...

# BinaryMutation class definition...

# BinaryCrossOver class definition...

@timer
def compress_image(input_image):

  pymils = PyMILS(BDM(ndim=2), min_size=0.5)

  problem = RowColSelection(input_image, pymils,
                            'min', dtype=torch.int8, initial_bounds=(0, 1))

  pop_size = 50
  tournament_size = 10
  mutation_prob = 0.1

  crossover_op = BinaryCrossOver(problem, tournament_size=tournament_size)
  mutation_op = BinaryMutation(problem, mutation_prob=mutation_prob)

  ga = GeneticAlgorithm(
    problem,
    popsize=pop_size,
    operators=[crossover_op, mutation_op]
  )

  original_bdm = pymils.calculate_bdm(input_image)

  best_objectives = []
  best_solutions = []
  percent_losses = []
  num_generations = 100
  for gen in range(num_generations):

    # GA step
    ga.step()

    # Track best solution
    values = ga.population.values
    evals = ga.population.evals
    best_index = torch.argmin(evals)
    best_solution = ga.population[best_index]
    best_objective = evals[best_index]
    print(f'Gen {gen} : best_objective : {best_objective}')
    best_objectives.append(best_objective)
    best_solutions.append(best_solution)

    # Get losses from best solution
    losses = ga.population[0].evals

    # Calculate percent loss from losses
    loss = sum(losses) / original_bdm * 100

    percent_losses.append(loss)

  evals = ga.population.evals
  # print(f"evals before mils(): {evals}")

  # Initialize empty lists
  sorted_indices = []
  sorted_losses = []

  best_solution = ga.population[0] # 0th index will be best solution

  # Evaluate loss of each bit
  for i, bit in enumerate(best_solution):

    if bit:

      # Bit is 1, so get loss for this index
      loss = pymils.evaluate_loss(input_image, i)

      # Append index and loss
      sorted_indices.append(i)
      sorted_losses.append(loss)


  # print(f'{sorted_indices}')
  # print(f'{sorted_losses}')
  # print(f"len sorted_losses before mils(): {len(sorted_losses)}")
  # print(f"len Sorted_indices before mils(): {len(sorted_indices)}")

  # Sort losses to align with indices
  sorted_losses, sorted_indices = zip(*sorted(zip(sorted_losses, sorted_indices)))

  # losses contains pre-computed bit losses could be stored in problem.eval_data
  # Pass to MILS
  compressed_image = pymils.mils(input_image, sorted_indices, sorted_losses)

  # print(f"len sorted_losses after mils(): {len(sorted_losses)}")
  # print(f"len Sorted_indices after mils(): {len(sorted_indices)}")

  # return compressed_image
  return compressed_image, sorted_indices, sorted_losses, best_objectives, best_solutions, percent_losses

# Call compress_image function
compressed_image, sorted_indices, sorted_losses, best_objectives, best_solutions, percent_losses = compress_image(data)

# Open file for dumping
filename = 'compressed_outputs.pkl'
import pickle
with open(filename, 'wb') as f:

  # Dump each output variable
  pickle.dump(compressed_image, f)
  pickle.dump(sorted_indices, f)
  pickle.dump(sorted_losses, f)
  pickle.dump(best_objectives, f)
  pickle.dump(best_solutions, f)
  pickle.dump(percent_losses, f)

with open(filename, 'rb') as f:

  compressed_image = pickle.load(f)
  sorted_indices = pickle.load(f)
  # and so on

# Call compress_image function
compressed_image, sorted_indices, sorted_losses, best_objectives, best_solutions, percent_losses \
  = compress_image(eca_images[131])

# Open file for dumping
# filename = 'observed_compressed.pkl'
filename = 'generated_compressed.pkl'
import pickle
with open(filename, 'wb') as f:

  # Dump each output variable
  pickle.dump(compressed_image, f)
  pickle.dump(sorted_indices, f)
  pickle.dump(sorted_losses, f)
  pickle.dump(best_objectives, f)
  pickle.dump(best_solutions, f)
  pickle.dump(percent_losses, f)

# Observed_data_arr
# Gen 99 : best_objective : ReadOnlyTensor([548.9260])
# len qualified_indices : 13
# qualified_indices : [194, 95, 26, 81, 1, 125, 44, 151, 186, 165, 18, 105, 170] qualified_losses : [0.33115347381681204, 6.684039078458227, 10.249126297857401, 12.557611064761659, 19.691730867774822, 21.048032600970146, 50.3214016344582, 50.81405626464766, 60.175352175668195, 65.17450356330119, 79.56882938655144, 84.50998576107577, 87.80015645971616]
# len row_indices : 12
# len col_indices : 1
# compress_image took 117.15 mins
# eca_images[131]

# Gen 99 : best_objective : ReadOnlyTensor([788.3813])
# len qualified_indices : 9
# qualified_indices : [188, 156, 104, 26, 30, 167, 57, 117, 83] qualified_losses : [0.06140054466413858, 70.47593098266876, 72.04683788816848, 105.89826117809204, 106.40922309736939, 106.41610948295468, 108.57960821523753, 109.19295251732851, 109.30105020438288]
# Max Allowed Loss threshold exceeded!
# len row_indices : 9
# len col_indices : 0
# compress_image took 77.70 mins

# Observed_data_arr at 50 generations
# len qualified_indices : 34
# qualified_indices : [76, 75, 40, 95, 35, 4, 80, 85, 138, 63, 23, 91, 1, 137, 120, 125, 34, 5, 103, 78, 177, 159, 163, 130, 146, 127, 150, 171, 161, 90, 102, 105, 172, 48] qualified_losses : [0.1885527212289162, 0.839084533514324, 5.197182184775556, 6.684039078458227, 7.224779576889887, 8.456770719282758, 8.759774930168533, 11.124000229088779, 11.299266822743448, 11.785464288085677, 19.034133102456508, 19.66528591025599, 19.691730867774822, 20.186446869506653, 20.825820225466487, 21.048032600970146, 22.764923302240277, 22.859520986734424, 26.717464622513944, 34.89028233063527, 37.2897712186068, 40.41104903177711, 43.825090084108524, 44.3669312003276, 45.23284039511873, 45.57268893978289, 51.74032889694536, 64.0770808249481, 68.04218423247949, 73.56586294825047, 78.36046965731202, 84.50998576107577, 87.98794761176396, 104.80087874232868]
# Delta threshold exceeded!
# len row_indices : 34
# len col_indices : 1
# compress_image took 49.26 mins

# Gen 49 : best_objective : ReadOnlyTensor([1508.5940])
# len qualified_indices : 30
# qualified_indices : [76, 194, 75, 193, 40, 35, 80, 143, 85, 138, 81, 84, 155, 119, 98, 92, 137, 93, 120, 31, 125, 62, 107, 34, 38, 7, 103, 181, 185, 79] qualified_losses : [0.1885527212289162, 0.33115347381681204, 0.839084533514324, 2.3151772920382427, 5.197182184775556, 7.224779576889887, 8.759774930168533, 11.045023719239907, 11.124000229088779, 11.299266822743448, 12.557611064761659, 14.420173377880019, 16.725565609138357, 19.02981011821339, 19.631936518513612, 19.9441452832516, 20.186446869506653, 20.206298804827384, 20.825820225466487, 21.02625070375234, 21.048032600970146, 21.33418298586639, 22.097412054545202, 22.764923302240277, 23.11744880349943, 23.644465757286525, 26.717464622513944, 29.99725121145002, 30.399874925953554, 33.20300169136772]
# Delta threshold exceeded!
# len row_indices : 63
# len col_indices : 8
# compress_image took 36.21 mins
# Gen 79 : best_objective : ReadOnlyTensor([5385.4619])

# Gen 79 : best_objective : ReadOnlyTensor([1106.0326])
# len qualified_indices : 25
# qualified_indices : [89, 97, 131, 28, 29, 204, 9, 94, 74, 92, 93, 38, 50, 98, 132, 12, 67, 18, 167, 160, 178, 161, 164, 112, 17] qualified_losses : [1.8591521570715486, 4.723824781643998, 11.437969773885925, 11.983779525993668, 12.54915821342729, 14.795467172562894, 17.913683010280693, 22.421023462310586, 23.851851468115456, 25.055467269700785, 25.055467269700785, 25.946179768756338, 31.495289375407992, 32.037781848589475, 37.33241705758701, 38.026356092190326, 53.54007523725704, 64.43680594940543, 67.27299926147862, 69.60521454188893, 94.25534430949847, 97.09044227386039, 98.1219762597575, 107.42338901194216, 117.80149504621386]
# Delta threshold exceeded!
# len row_indices : 24
# len col_indices : 1
# compress_image took 102.69 mins

# Gen 99 : best_objective : ReadOnlyTensor([281.7768])
# len qualified_indices : 12
# qualified_indices : [76, 31, 41, 43, 85, 140, 141, 143, 6, 187, 116, 49] qualified_losses : [0.1885527212289162, 6.388801140866235, 7.8172791123142815, 7.8172791123142815, 11.124000229088779, 12.879561483290672, 12.879561483290672, 12.879561483290672, 22.859520986734424, 30.399874925953554, 51.74196021357784, 104.80087874232868]
# len row_indices : 12
# len col_indices : 0
# compress_image took 0.72 mins

# Gen 99 : best_objective : ReadOnlyTensor([119.2675])
# len qualified_indices : 4
# qualified_indices : [5, 39, 151, 82] qualified_losses : [4.196173174439707, 37.693231008098934, 38.18108217387112, 39.19702371774014]
# len row_indices : 4
# len col_indices : 0
# compress_image took 0.79 mins

best_objectives[-1]

# Create input image
# input_image = np.random.randint(2, size=(32,32))

compressed_image, sorted_indices, sorted_losses, best_objectives, best_solutions, percent_losses \
  = compress_image(eca_images[131])

compressed_generated = compressed_image
compressed_generated.shape

observed_data_arr

compressed_image, sorted_indices, sorted_losses, best_objectives, best_solutions, percent_losses \
  = compress_image(observed_data_arr)



"""### Compress all"""

compressed_images = {}

for rule1 in eca_images:
  try:
    if isinstance(eca_images[rule1], np.ndarray):
      # Compress single image
      img = eca_images[rule1]
      compressed, indices, losses, objs, sols, percents = compress_image(img)
      compressed_images[rule1] = compressed

  except KeyError:
    print(f"Key {rule1} not found, continuing...")
    continue

  else:
    # Rule1 contains dict, iterate over rules2
    for rule2 in eca_images[rule1]:
      try:
        if isinstance(eca_images[rule1][rule2], np.ndarray):
          # Compress single image
          img = eca_images[rule1][rule2]
          compressed, indices, losses, objs, sols, percents = compress_image(img)
          compressed_images[rule1][rule2] = compressed

      except KeyError:
        print(f"Key {rule1}[{rule2}] not found, continuing...")
        continue

      else:
        # Rule2 contains dict, iterate over rule3
        for rule3 in eca_images[rule1][rule2]:
          try:
            # Compress single image
            img = eca_images[rule1][rule2][rule3]
            compressed, indices, losses, objs, sols, percents = compress_image(img)
            compressed_images[rule1][rule2][rule3] = compressed

          except KeyError:
            print(f"Key {rule1}[{rule2}][{rule3}] not found, continuing...")
            continue



"""### Rule Selection Problem"""

from evotorch import Problem, Solution

# Define problem
class RuleSelection(Problem):

  def __init__(self, image, pymils,
               objective_sense,
               dtype,
               initial_bounds):

    self.target_image = image
    self.pymils = pymils
    solution_length = 2 * 8 # 1 rules, each 8 bits long, None is not allowed
    #solution_length = 3 * 9 # 3 rules, each 9 bits long to cater for None

    super().__init__(
      objective_sense,
      solution_length=solution_length,
      dtype=dtype,
      initial_bounds=initial_bounds
    )

  def _evaluate(self, solution: Solution):
    evals = objective_rs(solution, self.target_image, self.pymils)
    solution.set_evals(evals)

  def generate_batch(self, pop_size):

    rules = [
      [100, 101],
      [101, 102],
      [102, 103],
      [104, 105],
    ]

    initial_solutions = []
    for _ in range(pop_size):
      rule1, rule2 = random.choice(rules)
      bits = encode_rules(rule1, rule2)
      initial_solutions.append(bits)

    batch = SolutionBatch(
      self,
      popsize=pop_size,
      empty=True
    )

    batch.set_values(
      torch.tensor(initial_solutions, dtype=torch.uint8)
    )

    return batch

def decode_rules(bits):
  rule1 = int(''.join(map(str, bits[0:8])), 2)
  rule2 = int(''.join(map(str, bits[9:17])), 2)
  return (rule1, rule2)

def encode_rules(rule1, rule2):
  rule1_bits = f'{rule1:08b}'
  rule2_bits = f'{rule2:08b}'
  bits = [int(x) for x in rule1_bits + rule2_bits]
  return bits

# Rule Selection and Matching fitness function
def objective_rs(solution, target_image, pymils):

  bits = solution.values.numpy()
  print(f'objective_rs : bits are {bits}')
  bits_list = bits.tolist()

  # Decode rules
  rule1, rule2 = decode_rules(bits_list)
  print(f'objective_rs : rule1 is {rule1} and rule2 is {rule2}')

  try:
    image = eca_images[rule1][rule2]
    # compressed_image, sorted_indices, sorted_losses, best_objectives, best_solutions, percent_losses \
    #   = compress_image(image)
  except KeyError:
    print(f'objective_rs : KeyError caught rule1 is {rule1} rule2 is {rule2}')
    return 10000.
  except Exception as e:
    print(f'objective_rs : Error caught rule1 is {rule1} rule2 is {rule2}')
    print(type(e))
    print(e)
    return 10000.

  # Calculate BDM
  target_bdms = pymils.calculate_bdm(target_image) # assume compressed
  image_bdms = pymils.calculate_bdm(image) # compressed image

  # Return difference in BDMs
  return torch.abs(torch.tensor(target_bdms) - torch.tensor(image_bdms))

eca_images[41][0][0].shape





"""### Match O and G images

"""

# Integrating all the above into here !
import torch
from evotorch import Problem, Solution, SolutionBatch
from evotorch.algorithms import GeneticAlgorithm
from evotorch.operators import Operator
from evotorch.operators import CrossOver
import random

# PyMILS class definition...

# RuleSelection class definition...

# BinaryMutation class definition...

# BinaryCrossOver class definition...

@timer
def match_image(input_image):

  pymils = PyMILS(BDM(ndim=2), min_size=0.5)

  problem = RuleSelection(input_image, pymils,
                            'min', dtype=torch.int8, initial_bounds=(0, 1))

  pop_size = 100
  tournament_size = 10
  mutation_prob = 0.1

  crossover_op = BinaryCrossOver(problem, tournament_size=tournament_size)
  mutation_op = BinaryMutation(problem, mutation_prob=mutation_prob)

  ga = GeneticAlgorithm(
    problem,
    popsize=pop_size,
    operators=[crossover_op, mutation_op]
  )

  # original_bdm = pymils.calculate_bdm(input_image)

  num_generations = 50
  for gen in range(num_generations):

########
#    break
########

    # GA step
    ga.step()

    # Track best solution
    # values = ga.population.values
    # evals = ga.population.evals
    # best_index = torch.argmin(evals)
    # best_solution = ga.population[best_index]
    # rule1, rule2 = decode_rules(best_solution.values.numpy().tolist())
    # print(f'RS Gen {gen} : Rule1 , Rule2 : {rule1} {rule2}')
    # best_objective = evals[best_index]
    # print(f'RS Gen {gen} : Best_objective : {best_objective}')
    # best_objectives.append(best_objective)
    # best_solutions.append(best_solution)

  # best_solution = ga.population[0] # 0th index will be best solution

  solutions = ga.population

  return solutions

# Testing generate_batch()
solutions = match_image(observed_original)

solutions.evals

best_rule_pairs = []
best_objectives_temp = []
for value, fitness in zip(solutions.values, solutions.evals):
  rule1, rule2 = decode_rules(value.numpy().tolist())
  # print (f'rule1, rule2 : {rule1} {rule2} fitness : {fitness}')
  best_rule_pairs.append((rule1,rule2))
  best_objectives_temp.append(fitness)

len(best_rule_pairs)

best_rule_pairs

"""### Visualisation

#### Loss variation across dimensions of an input image
"""

# plot loss variation across dimensions of an input image
# Input image shape
import matplotlib.pyplot as plt

input_image = observed_data_arr

pymils = PyMILS(BDM(ndim=2), min_size=0.5)

rows, cols = input_image.shape

row_losses = []
col_losses = []

solution = best_solutions[-1]
#for _, solution in enumerate(solutions):

for i in range(rows):
  if solution[i]:
    row_loss = pymils.evaluate_loss(input_image, i)
    row_losses.append(row_loss)

for j in range(cols):
  if solution[j+rows]:
    col_loss = pymils.evaluate_loss(input_image, j+rows)
    col_losses.append(col_loss)

# Plot losses
fig, axs = plt.subplots(2)

fig.suptitle("Loss variation across image dimensions")

fig.subplots_adjust(hspace=0.5)

axs[0].plot(row_losses)
axs[0].set_title("Row losses")
axs[0].set_xlabel("Index")
axs[0].set_ylabel("Loss")

axs[1].plot(col_losses)
axs[1].set_title("Col losses")
axs[1].set_xlabel("Index")
axs[1].set_ylabel("Loss")

plt.show()

"""#### Information Content before and after compression"""

compressed_image.shape

compressed_observed = compressed_image

pwd

# grouped bar plot - information content - before and after compression
import matplotlib.pyplot as plt
import numpy as np
import pickle

pymils = PyMILS(BDM(ndim=2), min_size=MIN_SIZE)

with open('observed_compressed.pkl', 'rb') as f:
  compressed_observed = pickle.load(f)

with open('generated_compressed.pkl', 'rb') as f:
  compressed_generated = pickle.load(f)

# Calculate BDM complexity
real_before_bdm = pymils.calculate_bdm(observed_data_arr)
real_after_bdm = pymils.calculate_bdm(compressed_observed)

sim_before_bdm = pymils.calculate_bdm(eca_images[131])
sim_after_bdm = pymils.calculate_bdm(compressed_generated)

# Plot grouped bar chart - bar heights based on BDM
index = np.arange(2)
bar_width = 0.35

plt.bar(index, [real_before_bdm, real_after_bdm], width=bar_width, label='Real')
plt.bar(index + bar_width, [sim_before_bdm, sim_after_bdm], width=bar_width, label='Simulated')

plt.xticks(index + bar_width/2, ('Before', 'After'))
# plt.legend(loc='lower right')
plt.legend()

plt.ylabel('Information Content')
plt.title('Information Content Before and After Compression')

plt.show()

# Calculate compression ratios
real_cmp_ratio = real_after_bdm / real_before_bdm
sim_cmp_ratio = sim_after_bdm / sim_before_bdm

# Print results
print(f"Real data compressed to {real_cmp_ratio*100:.2f}%")
print(f"Sim data compressed to {sim_cmp_ratio*100:.2f}%")

pwd

import matplotlib.pyplot as plt
import numpy as np
import pickle

pymils = PyMILS(BDM(ndim=2), min_size=MIN_SIZE)

with open('observed_compressed.pkl', 'rb') as f:
  compressed_observed = pickle.load(f)

with open('generated_compressed.pkl', 'rb') as f:
  compressed_generated = pickle.load(f)

# Calculate BDM complexity
real_before_bdm = pymils.calculate_bdm(observed_data_arr)
real_after_bdm = pymils.calculate_bdm(compressed_observed)

sim_before_bdm = pymils.calculate_bdm(eca_images[131])
sim_after_bdm = pymils.calculate_bdm(compressed_generated)

aid_original = abs(real_before_bdm-sim_before_bdm)
aid_compressed = abs(real_after_bdm-sim_after_bdm)

print(f'Algorithmic Information Distance between O and G (original): {aid_original:.2f}')
print(f'Algorithmic Information Distance between O and G (compressed): {aid_compressed:.2f}')

sim_before_bdm

sim_after_bdm

compressed_observed, compressed_generated

# heatmap - GA compression sequence
import matplotlib.pyplot as plt

# Sample data
data = eca_images[255][255]

# Solutions
solutions = best_solutions

# Plot
fig, ax = plt.subplots()

# Set aspect and extent
ax.set_aspect('equal')
im = ax.imshow(data)
im.set_extent([0, data.shape[1], 0, data.shape[0]])

# Initialize image
im = ax.imshow(data, interpolation='nearest')

# Track removed
removed = set()

# Iterate solutions
for solution in solutions:

  # Update removed
  new_removals = set(np.where(solution==1)[0])
  removed.update(new_removals)

  # Create mask
  mask = np.ones_like(data)
  for idx in removed:
    r = idx // data.shape[1]
    c = idx % data.shape[1]
    mask[r, c] = 0

  # Mask data
  masked_data = np.ma.masked_where(mask==0, data)

  # Clear and re-plot
  im.axes.clear()
  im = ax.imshow(masked_data, interpolation='nearest')

  plt.pause(0.5)

plt.title('GA Evolution')
plt.axis('off')
plt.show()

# retention of structure
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

# Sample original data
orig_data = observed_data_arr

# Compress with MILS
compressed = compressed_observed

# Apply PCA to original
pca = PCA(n_components=2)
orig_pca = pca.fit_transform(orig_data)

# Apply PCA to compressed
compressed_pca = pca.fit_transform(compressed)

# Plot PCA projections
fig, (ax1, ax2) = plt.subplots(1, 2)
ax1.scatter(orig_pca[:,0], orig_pca[:,1])
ax2.scatter(compressed_pca[:,0], compressed_pca[:,1])

ax1.set_title('Original')
ax2.set_title('Compressed')

# Shared title
fig.suptitle('Retention of structure using PCA', fontsize=16)

# Match axes limits
ax1.set_xlim(ax2.get_xlim())
ax1.set_ylim(ax2.get_ylim())

fig.tight_layout()
plt.show()

"""#### Original vs Compressed images"""

# original vs compressed
import matplotlib.pyplot as plt

fig, axes = plt.subplots(1, 2)

axes[0].imshow(observed_data_arr, cmap='gray')
axes[0].set_title('Original')

axes[1].imshow(compressed_observed, cmap='gray')
axes[1].set_title('Compressed')

fig.suptitle('Original vs Compressed Image')
plt.show()

# original vs compressed
import matplotlib.pyplot as plt

fig, axes = plt.subplots(1, 2)

axes[0].imshow(eca_images[131], cmap='gray')
axes[0].set_title('Original')

axes[1].imshow(compressed_generated, cmap='gray')
axes[1].set_title('Compressed')

fig.suptitle('Original vs Compressed Image')
plt.show()

"""#### Sorted information losses over rows/cols"""

# After GA completes
def plot_sorted_losses(input_image, sorted_indices, sorted_losses):

  # Get input image shape
  num_rows = input_image.shape[0]

  row_losses = []
  row_indices = []

  col_losses = []
  col_indices = []

  for i,idx in enumerate(sorted_indices):

    loss = sorted_losses[i]

    if idx < num_rows:
      # index is in rows
      row_losses.append(loss)
      row_indices.append(idx)

    else:
      # index is in cols
      col_losses.append(loss)
      col_indices.append(idx-num_rows)

  # Plot losses
  fig, axs = plt.subplots(2)

  fig.suptitle("Loss variation across image dimensions")

  fig.subplots_adjust(hspace=0.5)

  axs[0].plot(row_indices, row_losses)
  axs[0].set_title("Row losses")
  axs[0].set_xlabel("Index")
  axs[0].set_ylabel("Loss")

  axs[1].plot(col_indices, col_losses)
  axs[1].set_title("Col losses")
  axs[1].set_xlabel("Index")
  axs[1].set_ylabel("Loss")

  plt.show()

# Visualisation for Observed
plot_sorted_losses(observed_data_arr, sorted_indices, sorted_losses)

# Information loss over rows and coloumns separately
input_image = observed_data_arr

# Get input image shape
num_rows = input_image.shape[0]

row_losses = []
row_indices = []

col_losses = []
col_indices = []

for i,idx in enumerate(sorted_indices):

  loss = sorted_losses[i]

  if idx < num_rows:
    # index is in rows
    row_losses.append(loss)
    row_indices.append(idx)

  else:
    # index is in cols
    col_losses.append(loss)
    col_indices.append(idx-num_rows)

# Plot losses
# fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(10,15), dpi=150)
fig, axs = plt.subplots(nrows=2, figsize=(20,20), gridspec_kw={'height_ratios': [1, 3]})
fig.suptitle("Loss variation across image dimensions")

fig.subplots_adjust(hspace=0.5)

axs[0].imshow(input_image.T, cmap='gray')
for i, loss in zip(row_indices, row_losses):
  axs[0].vlines(i, 0, loss, colors='r')
axs[0].set_title("Row losses")
axs[0].set_xlabel("Index")
axs[0].set_ylabel("Loss")

# Make second subplot wider
# Adjust overall subplot params
fig.subplots_adjust(bottom=0.1, top=0.9)

axs[1].imshow(input_image, cmap='gray')
for i, loss in zip(col_indices, col_losses):
  axs[1].vlines(i, 0, loss, colors='r')
axs[1].set_title("Col losses")
axs[1].set_xlabel("Index")
axs[1].set_ylabel("Loss")

plt.show()

sorted_losses

sorted_indices

# Information loss over rows and coloumns separately
input_image = observed_data_arr

# Separate indices
row_indices = sorted_indices[:input_image.shape[0]]
col_indices = sorted_indices[input_image.shape[0]:]

# Extract losses based on sorted_losses order
row_losses = sorted_losses[:len(row_indices)]
col_losses = sorted_losses[len(row_indices):]

# Plot losses
fig, axs = plt.subplots(2)

fig.suptitle("Loss variation across image dimensions")

fig.subplots_adjust(hspace=0.5)

axs[0].imshow(input_image.T, cmap='gray')
for i, loss in zip(row_indices, row_losses):
  axs[0].vlines(i, 0, loss, colors='r')
axs[0].set_title("Row losses")
axs[0].set_xlabel("Index")
axs[0].set_ylabel("Loss")

axs[1].imshow(input_image, cmap='gray')
for i, loss in zip(col_indices, col_losses):
  axs[1].vlines(i, 0, loss, colors='r')
axs[1].set_title("Col losses")
axs[1].set_xlabel("Index")
axs[1].set_ylabel("Loss")

plt.show()

"""By plotting the information loss values overlaid on the rows and columns separately, we can gain some insights:

- It helps visualize which specific rows and columns were compressed earlier vs later in the MILS process. The ones with higher losses were removed first.

- We can see if there are any patterns or correlations between the spatial locations of high loss rows/cols and the structure of the input data.

For example, it may reveal:

- Horizontal or vertical stripes/bands of high loss areas, indicating redundant repetitive patterns.

- Isolated high loss spots, suggesting those rows/cols contained unique but less informative features.

- Clusters of high loss near image boundaries, where edge effects may introduce more redundancy.

- Alternating high/low loss structures, potentially corresponding to different underlying patterns or signal frequencies.

So in summary, these plots help:

1) Validate the MILS process by showing losses correlate to redundant vs unique areas

2) Reveal any emergent spatial patterns in how redundant/unique information is distributed

3) Provide clues about the inherent structures, patterns or generative rules underlying the input data

The loss variation visualization thus gives additional qualitative insights into how the input data is compressed by MILS in an information-theoretically optimal way.
"""

def plot_step_losses(input_image, sorted_indices):

  # Setup subplots
  fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(12, 6))
  plt.subplots_adjust(wspace=0.3, hspace=0.4)

  # Original image
  axes[0,0].imshow(input_image, cmap='gray')
  axes[0,0].set_title('Original')

  # Initialize index counter
  idx = 0
  temp_image = input_image
  # Compression steps
  for i in range(4):

    # Get next index
    next_idx = sorted_indices[idx]
    # Remove next bit
    temp_image = pymils.delete(temp_image, next_idx)
    # Increment counter
    idx += 1

    axes[0,i+1].imshow(temp_image, cmap='gray')
    axes[0,i+1].set_title(f'Compression Step {i+1}')


  # Second row of plots
  for i in range(5):

    # Get next index
    next_idx = sorted_indices[idx]
    # Remove next bit
    temp_image = pymils.delete(temp_image, next_idx)
    # Increment counter
    idx += 1

    axes[1,i].imshow(temp_image, cmap='gray')
    axes[1,i].set_title(f'Compression Step {i+5}')


  plt.suptitle("MILS Compression Steps")
  plt.show()

# Visualisation for O
plot_sorted_losses(sorted_losses)
plot_step_losses(observed_data_arr, sorted_indices)

# Visualisation for G eca_images[131]
plot_sorted_losses(sorted_losses)
plot_step_losses(observed_data_arr, sorted_indices)

"""#### Best Objective over Generations"""

import matplotlib.pyplot as plt

# using best_objectives returned by compress_image() for O

# Plot best objective vs generation
plt.plot(best_objectives)
plt.xlabel('Generation')
plt.ylabel('Best Objective')
plt.title('Best Objective over Generations')
plt.show()



import matplotlib.pyplot as plt

# using best_objectives returned by compress_image() for G

# Plot best objective vs generation
plt.plot(best_objectives)
plt.xlabel('Generation')
plt.ylabel('Best Objective')
plt.title('Best Objective over Generations for G')
plt.show()

# Assume percent_losses list collected stats

import matplotlib.pyplot as plt

# Plot percent loss over generations
plt.plot(percent_losses)

plt.xlabel('Generation')
plt.ylabel('Percent Information Loss')
plt.title('Information Loss over Generations')

plt.show()

import matplotlib.pyplot as plt
import numpy as np

def overlay_mask(img, mask):

  # Convert 2D image to 3D for color
  height, width = img.shape[:2]

  # Repeat values along channel dim
  img_3d = np.repeat(img[...,np.newaxis], 3, axis=-1)

  masked = img_3d.copy()

  for i, bit in enumerate(mask):

    row = i // width
    col = i % width

    # if bit == 1:

    #   # Retained - Red color
    #   masked[row, col, 0] = 1
    #   masked[row, col, 1] = 0
    #   masked[row, col, 2] = 0

    # else:

    #   # Deleted - Green color
    #   masked[row, col, 0] = 0
    #   masked[row, col, 1] = 1
    #   masked[row, col, 2] = 0

    if bit == 1:
      masked[row, col] = [1, 0, 0]  # Red

    else:
      masked[row, col] = [0, 1, 0] # Green

  return masked





num_generations = 10 # check with 'Putting themn together' section
for gen in range(num_generations):

  if gen % 5 == 0:

    mask = best_solutions[gen]
    caption = f'Gen {gen}\n'

    # Overlay mask
    masked = overlay_mask(input_image, mask)

    fig, ax = plt.subplots()
    ax.imshow(masked)
    ax.set_title(caption)
    plt.show()

    fig.savefig(f'gen-{gen}.png')
    plt.clf()

import matplotlib.pyplot as plt
import numpy as np

def overlay_mask(img, mask):

  height, width = img.shape[:2]

  print("Input image shape:", img.shape)

  img_3d = np.repeat(img[...,np.newaxis], 3, axis=-1)

  masked = img_3d.copy()

  for i, bit in enumerate(mask):

    row = i // width
    col = i % width

    if bit == 1:
      masked[row, col] = [1, 0, 0]

    else:
      masked[row, col] = [0, 1, 0]

  print("Masked array shape:", masked.shape)
  print("Sample masked value:", masked[0,0])

  return masked


num_generations = 10

for gen in range(num_generations):

  if gen % 5 == 0:

    solution = best_solutions[gen]
    mask = solution.values
    mask = mask.numpy()

    print("Sample mask value:", mask[0])

    masked = overlay_mask(input_image, mask)

    print("Masked min, max values:", masked.min(), masked.max())

    fig, ax = plt.subplots(figsize=(10,10), dpi=100)

    img = masked
    ax.imshow(img, cmap=None, vmin=0, vmax=1)

    ax.set_title(f'Gen {gen}')
    plt.show()

"""## Multi-level O-G Matching

We want to be able to break down a long running (days if not weeks) GA process with thousands of thousands of 2D arrays in search of the best match measured by the algorithmic complexity distance between O and G, in a muli-level distributed genetic algorithm.  To achieve that we introduced a few concepts below.

1. Batch Size.  The master task constructs a list of all filenames of all images to be searched.  Filenames follow a simple convention of eca_images{rule1}_{rule2}.pkl.  The list of filenames is thus [(rule1,rule2),()...()].  Partition the list into batches of maximum size indicated by BATCH_SIZE.

2. Levels. Now we have a list of rule tuples for each batch, identified by a batch index. A batch of rule tuples can be searched using a separate Google Colab account, thus achieving scaling as many as the number of Google Colab accounts available.  Thus, there will be multiple levels of hierarachy of GAs with the highest level containing 1 usual GA to aggregate all the best solutions from the level below in a final search for the global best solution.

3. State. There are 2 distinct states in this multi-level distributed GA.
  
  3.1 The list of rule pairs in a partition using batch size defined above represent the starting set of rule pairs for each level.This state is stored in batch_{level}_{batch_idx}.pkl file.

  3.2 State of a GA such as the best solutions found is stored using standard naming conventions results{LEVEL}_{BATCH_IDX}.pkl so that a GA with the associated state can be loaded and resumed by any Google Colab accounts if need be.  Therefore, save_state(level, batch_idx, rule_pairs) and load_state(level, batch_idx, rule_pairs) are complementary functions that implement state persistence.

4. Aggregation at a level.  We will need a aggregate_state() utility that could read any number of state .pkl files as explained above to collect all rule_pairs into one master list for a particular level so that jobs can be spawned off again to search the rule pairs space locally.

The general flow of the process is as follows:

1. Constructs a master list of ECA rule pairs

2. Partition the master list into batches that can be persisted as separate {level}_{batch_idx} pkl files

3. Now one or more of these pkl files can be moved to a Google Colab account to perform a local search and match

4. Next any number of state pkl files can be gathered into one folder and then step #1 above repeated for each level

5. Finally, when the master list of ECA rule pairs contains fewer than BATCH_SIZE number of them, they can be searched and matched in one final GA run.


"""

NUM_LEVELS = 3
LEVEL = 0
BATCH_IDX = 0
BATCH_SIZES = [10000, 500, 100]
BATCH_SIZE = BATCH_SIZES[0]
INPUT_PATH = '/content/drive/MyDrive/Colab Notebooks/Capstone/eca_images_1r'

"""### 1. Constructs a master list of ECA rule pairs

"""

import re
import os

name_patterns = [
  r'eca_images(?P<rule1>[0-9]{1,3}).pkl',
  r'eca_images(?P<rule1>[0-9]{1,3})_(?P<rule2>[0-9]{1,3}).pkl',
  r'eca_images(?P<rule1>[0-9]{1,3})_(?P<rule2>[0-9]{1,3})_(?P<rule3>[0-9]{1,3}).pkl'
]

def parse_filename(filename):

  filename = os.path.basename(filename)

  for pattern in name_patterns:
    match = re.match(pattern, filename)
    if match:
      rule1 = int(match.group("rule1"))

      if "rule2" in match.groupdict():
        rule2 = int(match.group("rule2"))
      else:
        rule2 = None

      if "rule3" in match.groupdict():
        rule3 = int(match.group("rule3"))
      else:
        rule3 = None

      return (rule1, rule2, rule3)

  return (None, None, None)

import re, os, glob

# Function to get list of subfolders
def get_subfolder_list(folder_path):

  subfolders = []

  for entry in os.listdir(folder_path):

    full_path = os.path.join(folder_path, entry)

    if os.path.isdir(full_path):
      subfolders.append(full_path)

  return subfolders

def get_filenames(folder):

  file_count = 0
  filenames = []

  name_patterns = [
    'eca_images*.pkl',
    'eca_images*_*.pkl',
    'eca_images*_*_*.pkl'
  ]

  for pattern in name_patterns:
    files = glob.glob(os.path.join(folder, pattern))
    filenames.extend(files)
    file_count += len(files)

  unique_filenames = set(filenames)

  print(f"Total files in {folder}: {len(unique_filenames)}")

  return unique_filenames

def parse_batch_file(filename):

  match = re.match("batch_(?P<level>\d+)_(?P<batch>\d+)", filename)

  if not match:
    raise ValueError("Invalid filename format")

  level = int(match.group("level"))
  batch = int(match.group("batch"))

  return level, batch

def parse_batch_file_path(path):

  filename = os.path.basename(path)

  level, batch = parse_batch_file(filename)

  return level, batch

def get_rule_pairs(source, path=None):

  if source == "generate":

    # Generate all possible rule pairs
    rules = range(256) # Elementary Cellular Automata

    rule_pairs = []

    for r1 in rules:
      for r2 in rules:
        rule_pairs.append((r1, r2))

  elif source == "image_files":

    # Get rule pairs from existing image files
    # scan all subfolders to gather all unique filenames
    file_count = 0
    filenames_all = []

    subfolders = get_subfolder_list(path)
    print(f"subfolders scanned : {subfolders}")

    for subfolder in subfolders:
      filenames = get_filenames(subfolder)
      filenames_all.extend(filenames)

    rule_pairs = []
    for filename in filenames_all:
      # Parse filename
      rule1, rule2, rule3 = parse_filename(filename)
      rule_pairs.append((rule1, rule2))

  elif source == "batch_files":

    rule_pairs = []

    state_file_paths = glob.glob(f"{path}/batch_*.pkl")

    for path in state_file_paths:

      level, batch = parse_batch_file_path(path)

      state_file = f"batch_{level}_{batch}.pkl"

      with open(state_file, 'rb') as f:
        batch_rules = pickle.load(f)

        rule_pairs.extend(batch_rules)

  else:

    raise ValueError("Invalid source")


  return rule_pairs

rule_pairs = get_rule_pairs("generate", path=INPUT_PATH)
len(rule_pairs)

"""### 2. Partition into batches"""

import pickle

def partition_and_persist(rule_pairs, batch_size, level):

  batches = []

  for i in range(0, len(rule_pairs), batch_size):
    batch = rule_pairs[i:i+batch_size]
    batches.append(batch)

  for i, batch in enumerate(batches):

    batch_file = f"batch_{level}_{i}.pkl"

    with open(batch_file, 'wb') as f:
      pickle.dump(batch, f)

  print(f"{len(batches)} batches created for level {level}")

  return batches

batches = partition_and_persist(rule_pairs, batch_size=BATCH_SIZE, level=LEVEL)
num_batches = len(batches)

len(batches[6])

ls

"""### Get Batch Paths"""

# Determine a batch of image filenames

def get_batch_paths(subfolders, batch_size=BATCH_SIZE, batch_idx=BATCH_IDX):
  paths = []
  num_subfolders = BATCH_SIZE // 1000 # 1000 image files in a subfolder
  for i in range(num_subfolders*BATCH_IDX,num_subfolders*(BATCH_IDX+1)): # no of subfolders

    if i == len(subfolders):
      print('Reached the end of subfolders list')
      break

    filenames = get_filenames(subfolders[i])
    for filename in filenames:

      full_path = os.path.join(subfolders[i], filename)
      if full_path is None:
        print("Filename not found!")
      else:
        paths.append(full_path)

  return paths

subfolders = get_subfolder_list(INPUT_PATH)

# BATCH_IDX = 4
paths = get_batch_paths(subfolders,batch_size=BATCH_SIZE, batch_idx=BATCH_IDX)

"""### Load Batch Images"""

import pickle
@timer
def load_batch(batch):

  total_images = 0
  eca_images = {}

  for filename in batch:

    print(f'filename : {filename}')
    # Parse filename
    rule1, rule2, rule3 = parse_filename(filename)

    try:
      with open(filename, 'rb') as f:
        ca = pickle.load(f)

      # Store ca under rule keys
      if rule3 is not None:
        if rule1 not in eca_images:
          eca_images[rule1] = {}
        if rule2 not in eca_images[rule1]:
          eca_images[rule1][rule2] = {}
        eca_images[rule1][rule2][rule3] = ca
        total_images += 1

      elif rule2 is not None:
        if rule1 not in eca_images:
          eca_images[rule1] = {}
        eca_images[rule1][rule2] = ca
        total_images += 1

      else:
        eca_images[rule1] = ca
        total_images += 1

    except OSError:
      print(f"Error opening file {filename}")
    except pickle.PickleError:
      print(f"Error loading pickle from {filename}")

  return eca_images, total_images

"""### Save Best Rule Pairs"""

import pickle

def save_best_rule_pairs(best_rule_pairs, best_objectives, level, batch_idx):

  # Store results in a dictionary
  results = {
    'best_rule_pairs': best_rule_pairs,
    'best_objectives': best_objectives
  }

  # Save to a pickle file
  with open(f'results_{level}_{batch_idx}.pkl', 'wb') as f:
    pickle.dump(results, f)

# Usage:
# best_rule_pairs = [(rule1, rule2), (rule3, rule4), ...]
# best_objectives = [0.1, 0.2, ...]

# save_ga_results(best_rule_pairs, best_objectives, level=0, batch_idx=1)

"""### Run Centralised GA"""

import pickle

with open('observed_original.pkl', 'rb') as f:
  observed_original = pickle.load(f)

observed_original.shape

print(f'Level : {LEVEL}, Batch size : {BATCH_SIZE}, Batch Index : {BATCH_IDX}')

# If we are able to run all GAs in one account ...

rule_pairs = get_rule_pairs("generate", path=INPUT_PATH)
len(rule_pairs)

batches = partition_and_persist(rule_pairs, batch_size=BATCH_SIZE, level=LEVEL)
num_batches = len(batches)

# Get list of all subfolders
subfolders = get_subfolder_list(INPUT_PATH)

for batch_idx in range(num_batches):

  paths = get_batch_paths(batch_size=BATCH_SIZE, batch_idx=batch_idx)

  eca_images, total_no_images = load_batch(paths)

  solutions = match_image(observed_original)

  best_rule_pairs = []
  best_objectives_temp = []
  for value, fitness in zip(solutions.values, solutions.evals):
    rule1, rule2 = decode_rules(value.numpy().tolist())
    # print (f'rule1, rule2 : {rule1} {rule2} fitness : {fitness}')
    best_rule_pairs.append((rule1,rule2))
    best_objectives_temp.append(fitness)

  save_best_rule_pairs(best_rule_pairs, best_objectives_temp, level=LEVEL, batch_idx=BATCH_IDX)

"""### Run Local Distributed GAs

20th Sept: run BATCH_IDX 4 and 5, combine and run the final GA to test the process end to end.
"""

subfolders = get_subfolder_list(INPUT_PATH)

INPUT_PATH

#BATCH_IDX = 5
paths = get_batch_paths(subfolders, batch_size=BATCH_SIZE, batch_idx=BATCH_IDX)

eca_images, total_no_images = load_batch(paths)

total_no_images

solutions = match_image(observed_original)

"""### Verification"""

solutions.evals

best_rule_pairs = []
best_objectives_temp = []
for value, fitness in zip(solutions.values, solutions.evals):
  rule1, rule2 = decode_rules(value.numpy().tolist())
  # print (f'rule1, rule2 : {rule1} {rule2} fitness : {fitness}')
  best_rule_pairs.append((rule1,rule2))
  best_objectives_temp.append(fitness)

save_best_rule_pairs(best_rule_pairs, best_objectives_temp, level=LEVEL, batch_idx=BATCH_IDX)

"""### 4. Consolidate all intermediate states


"""

# consolidate all result_*.pkl files from individual Google Colab accounts to a single account

import glob
import pickle

results_files = glob.glob('results_*.pkl')

final_rule_pairs = []
final_objectives = []

for file in results_files:

  print(f'results file : {file}')

  with open(file, 'rb') as f:
    results = pickle.load(f)

  best_rule_pairs = results['best_rule_pairs']
  best_objectives = results['best_objectives']

  print(f'len(best_rule_pairs) : {len(best_rule_pairs)}')
  print(f'len(best_objectives) : {len(best_objectives)}')

  final_rule_pairs.extend(best_rule_pairs)
  final_objectives.extend(best_objectives)

# Save consolidated results
final_results = {
  'final_rule_pairs': final_rule_pairs,
  'final_objectives': final_objectives
}

with open('final_results.pkl', 'wb') as f:
  pickle.dump(final_results, f)

####################
# NOT USED for now #
####################
# Sort based on objectives
sorted_indices = sorted(range(len(final_objectives)), key=final_objectives.__getitem__)
final_rule_pairs = [final_rule_pairs[i] for i in sorted_indices]
final_objectives = [final_objectives[i] for i in sorted_indices]

# Remove duplicates
final_results = {}

for file in results_files:

  results = pickle.load(file)

  for rule, obj in zip(results['rules'], results['objs']):

    if rule not in final_results:
      final_results[rule] = obj

final_rule_pairs = list(final_results.keys())
final_objectives = list(final_results.values())


print(f"Loaded {len(final_rule_pairs)} consolidated rule pairs")



# Now run final GA
best_overall = run_ga(final_results)



"""### Consolidate Image Filenames
Collect filenames of elite rule pairs selected from distributed GAs in previous round
"""

with open('final_results.pkl', 'rb') as f:
  final_results = pickle.load(f)

final_rule_pairs = final_results['final_rule_pairs']
final_objectives = final_results['final_objectives']

len(final_rule_pairs)

# Construct image filenames
rule_pairs = final_rule_pairs

image_filenames = []
for r1, r2 in rule_pairs:
  filename = f'eca_images{r1}_{r2}.pkl'
  image_filenames.append(filename)

len(image_filenames)

image_filenames[200]

"""### Find Paths to Consolidated Images"""

# Get list of all subfolders
subfolders = get_subfolder_list(INPUT_PATH)

# Search all subfolders for filename
def find_image(filename):

  for subfolder in subfolders:
    full_path = os.path.join(subfolder, filename)
    if os.path.exists(full_path):
      return full_path

  return None

full_paths = []
for file in image_filenames:
  full_path = find_image(file)
  if full_path is None:
    print(f'Error locating {filename}')
  else:
    full_paths.append(full_path)

len(full_paths)

full_paths[200]

"""### Load Consolidated Images"""

eca_images, total_no_images = load_batch(full_paths)

total_no_images

eca_images[103][35]

for rule1, rule2 in final_rule_pairs:
  print(rule1, rule2)

"""### Best Rule Selection Problem"""

from evotorch import Problem, Solution

# Define problem
class BestRuleSelection(RuleSelection):

  def generate_batch(self, popsize):

    initial_solutions = []
    for _ in range(popsize):
      rule1, rule2 = random.choice(best_rule_pairs)
      bits = encode_rules(rule1, rule2)
      initial_solutions.append(bits)

    batch = SolutionBatch(
      self,
      popsize=len(initial_solutions),
      empty=True
    )

    batch.set_values(
      torch.tensor(initial_solutions, dtype=torch.uint8)
    )

    return batch



"""### Best Match Image"""

import torch
from evotorch import Problem, Solution, SolutionBatch
from evotorch.algorithms import GeneticAlgorithm
from evotorch.operators import Operator
from evotorch.operators import CrossOver
import random

@timer
def best_match_image(input_image):

  pymils = PyMILS(BDM(ndim=2), min_size=0.5)

  problem = BestRuleSelection(input_image, pymils,
                            'min', dtype=torch.int8, initial_bounds=(0, 1))

  pop_size = 500
  tournament_size = 10
  mutation_prob = 0.1

  crossover_op = BinaryCrossOver(problem, tournament_size=tournament_size)
  mutation_op = BinaryMutation(problem, mutation_prob=mutation_prob)

  ga = GeneticAlgorithm(
    problem,
    popsize=pop_size,
    operators=[crossover_op, mutation_op]
  )

  num_generations = 200
  for gen in range(num_generations):

    # GA step
    ga.step()

  solutions = ga.population

  return solutions

"""### 5. Run final GA"""

best_rule_pairs = final_rule_pairs # used in generate_batch() of BestRuleSelectionProblem

solutions = best_match_image(observed_original)

solutions.evals

best_rule_pairs = []
best_objectives_temp = []
for value, fitness in zip(solutions.values, solutions.evals):
  rule1, rule2 = decode_rules(value.numpy().tolist())
  # print (f'rule1, rule2 : {rule1} {rule2} fitness : {fitness}')
  best_rule_pairs.append((rule1,rule2))
  best_objectives_temp.append(fitness)

len(best_rule_pairs)

best_rule_pairs #(163,115)

from collections import Counter

rule_pairs = best_rule_pairs

counter = Counter(tuple(pair) for pair in rule_pairs)
most_common = counter.most_common(1)[0]
print(most_common)

"""### Visualisation"""

ca = eca_images[r1][r2]

import matplotlib.pyplot as plt

# Function to plot a 2D cellular automata array
def plot_cellular_automata(ca_array):

  plt.imshow(ca_array, cmap='gray', interpolation='nearest')

  plt.xlabel('Cells')
  plt.ylabel('Time Steps')

  plt.xticks(size=8)
  plt.yticks(size=8)

  ticks = range(0, 32, 8)
  labels = [f'Bit {i}' for i in ticks]

  plt.xticks(ticks, labels, rotation=45)

  plt.savefig('ca_pattern.png')
  plt.show()

plot_cellular_automata(ca)

"""## Visualisation

#### Target vs Candidate Images
"""

import matplotlib.pyplot as plt

def generate_image(bits):

  # Decode rules
  rule1, rule2, rule3 = decode_rules(bits)
  print(f'generate_image : rule1 is {rule1}')
  print(f'generate_image : rule2 is {rule2}')
  print(f'generate_image : rule3 is {rule3}')

  # Look up eca image for rules
  if rule3 != None:
    image = eca_images[rule1][rule2][rule3]
  elif rule2 != None:
    image = eca_images[rule1][rule2]
  else:
    image = eca_images[rule1]

  return image

# Generate input image
input_image = observed_data_arr

pymils = PyMILS(BDM(ndim=2), min_size=0.5)

problem = RuleSelection(input_image, pymils,
                          'min', dtype=torch.int8, initial_bounds=(0, 1))

pop_size = 10
tournament_size = 2
mutation_prob = 0.1

crossover_op = BinaryCrossOver(problem, tournament_size=tournament_size)
mutation_op = BinaryMutation(problem, mutation_prob=mutation_prob)

ga = GeneticAlgorithm(
  problem,
  popsize=pop_size,
  operators=[crossover_op, mutation_op]
)

num_generations = 10
for gen in range(num_generations):

  # GA generation step
  ga.step()

  # Track best solution
  values = ga.population.values
  evals = ga.population.evals
  best_index = torch.argmin(evals)
  best_solution = ga.population[best_index]

  # Generate image from best solution
  best_image = generate_image(best_solution.values.numpy().tolist())

  # Create figure with subplots
  fig, axs = plt.subplots(1, 2, figsize=(10,10), dpi=100)

  # Show input and solution images
  axs[0].imshow(input_image, cmap='gray')
  axs[0].set_title('Input Image')

  axs[1].imshow(best_image, cmap='gray')
  axs[1].set_title(f'Best Solution - Gen {gen}')

  # Show/save figure
  plt.show()
  plt.savefig(f'gen_{gen}.png')

  # Clear figure for next gen
  plt.clf()

"""#### Best Objective over Generations"""

import matplotlib.pyplot as plt

# using best_objectives returned by compress_image()

# Plot best objective vs generation
plt.plot(best_objectives)
plt.xlabel('Generation')
plt.ylabel('Best Objective')
plt.title('Best Objective over Generations')
plt.show()

import matplotlib.pyplot as plt

# Generate input image
input_image = observed_data_arr

pymils = PyMILS(BDM(ndim=2), min_size=0.5)

problem = RuleSelection(input_image, pymils,
                          'min', dtype=torch.int8, initial_bounds=(0, 1))

pop_size = 10
tournament_size = 2
mutation_prob = 0.1

crossover_op = BinaryCrossOver(problem, tournament_size=tournament_size)
mutation_op = BinaryMutation(problem, mutation_prob=mutation_prob)

ga = GeneticAlgorithm(
  problem,
  popsize=pop_size,
  operators=[crossover_op, mutation_op]
)

best_objectives = []

num_generations = 10
for gen in range(num_generations):

  # GA generation step
  ga.step()

  # Track best solution
  values = ga.population.values
  evals = ga.population.evals
  best_index = torch.argmin(evals)
  best_solution = ga.population[best_index]
  best_objective = evals[best_index]
  best_objectives.append(best_objective)


# Plot
plt.plot(range(num_generations), best_objectives)
plt.ylabel('Best Objective Value')
plt.xlabel('Generation')
plt.title('Optimization Progress')

plt.show()

"""#### Population Distribution at each Generation"""



import matplotlib.pyplot as plt

# Generate input image
input_image = observed_data_arr

pymils = PyMILS(BDM(ndim=2), min_size=0.5)

problem = RuleSelection(input_image, pymils,
                          'min', dtype=torch.int8, initial_bounds=(0, 1))

pop_size = 10
tournament_size = 2
mutation_prob = 0.1

crossover_op = BinaryCrossOver(problem, tournament_size=tournament_size)
mutation_op = BinaryMutation(problem, mutation_prob=mutation_prob)

ga = GeneticAlgorithm(
  problem,
  popsize=pop_size,
  operators=[crossover_op, mutation_op]
)

best_objectives = []

num_generations = 10
for gen in range(num_generations):

  # GA generation step
  ga.step()

  # Track best solution
  values = ga.population.values
  evals = ga.population.evals
  best_index = torch.argmin(evals)
  best_solution = ga.population[best_index]
  best_objective = evals[best_index]
  best_objectives.append(best_objective)

  objectives = evals # Get all objectives

  plt.hist(objectives, bins=20)
  plt.title(f"Generation {gen}")
  plt.xlabel("Objective")
  plt.ylabel("Frequency")

  plt.savefig(f"gen_{gen}_hist.png")



plt.show()

plt.clf()
plt.close()

"""#### Animate Evolution"""

import matplotlib.animation as animation

def animate(i):
    # Clear axes
    axs[0].clear()
    axs[1].clear()

    # Set title to show generation
    axs[0].set_title(f"Generation {i}")

    # Plot input image
    axs[0].imshow(input_image)

    # Track best solution
    values = ga.population.values
    evals = ga.population.evals
    best_index = torch.argmin(evals)
    best_solution = ga.population[best_index]
    best_objective = evals[best_index]
    # Get current population
    pop = ga.population

    # Plot objective values
    axs[1].hist(best_objective)
    axs[1].set_title('Objective values')

    # Highlight best solution
    axs[1].vlines(best_solution, 0, 1, colors='r')

    # Plot best solution image
    best_img = generate_image(best_solution)
    axs[0].imshow(best_img)

# Generate input image
input_image = observed_data_arr

pymils = PyMILS(BDM(ndim=2), min_size=0.5)

problem = RuleSelection(input_image, pymils,
                          'min', dtype=torch.int8, initial_bounds=(0, 1))

pop_size = 10
tournament_size = 2
mutation_prob = 0.1

crossover_op = BinaryCrossOver(problem, tournament_size=tournament_size)
mutation_op = BinaryMutation(problem, mutation_prob=mutation_prob)

ga = GeneticAlgorithm(
  problem,
  popsize=pop_size,
  operators=[crossover_op, mutation_op]
)


fig, axs = plt.subplots(1, 2, figsize=(10,5))

num_generations = 10
for gen in range(num_generations):

  # GA generation step
  ga.step()

  # Animate frame
  animate(gen)


# Create animation
anim = animation.FuncAnimation(fig, animate, frames=num_generations)

plt.show()

"""#### 3 plots to showcase findings
1. Accuracy of modeling

- Call generate_eca() to produce patterns from best matching rules
- Plot original vs generated side-by-side for visual comparison
- Compute/display information distance metric

2. Best matching rules

- Print/plot sample patterns from top rules
- Annotation helps interpretation

3. Causal decomposition

- Perturb rule components using perturb_component()
- Plot original vs perturbed patterns
- Annotation reveals causal influences

"""

import pickle

with open('observed_original.pkl', 'rb') as f:
  observed_original = pickle.load(f)

"""The perturb_rule function is aiming to perturb/modify one of the ECA rules that was used to generate the original cellular automata pattern, in order to observe how that impacts the overall pattern.

Specifically, it is taking the following inputs:

- ca: The original CA pattern that was generated
- rule_idx: The index of the rule to perturb (0 for first rule, 1 for second rule etc)
- new_rule: The new rule value to replace the old one

It then regenerates the CA pattern while keeping all rules the same, except swapping out the rule at index rule_idx for the new rule value new_rule.

By comparing the original and perturbed patterns, it allows analyzing how sensitive the overall emergent behavior is to changes in the individual ECA rules.

Some examples of insights it could provide:

- If a small rule change causes drastic differences, that rule likely plays a key causal role.

- If patterns remains similar, that rule may have weak influence on the behavior.

- It could identify rules more responsible for generating certain localized structures.

So in summary, perturb_rule acts as a tool for causal analysis, by observing how localized perturbations to rules impact the system-level patterns over time. This helps characterize what roles individual rules play in driving the complex emergent behavior.
"""

import numpy as np
from scipy.signal import convolve2d

def perturb_rule(ca, rules, rule_idx, new_rule):

  kernels = np.ones((3,3))

  for r in range(ca.shape[0]-2):
    for c in range(ca.shape[1]-2):

      neighborhood = convolve2d(ca, kernels,
                              mode='valid',
                              boundary='symm')

      # rest of function
      bool_neighborhood = neighborhood.astype(bool).flatten()

      if rule_idx == 0:
        perturbed[r,c] = rule_lookup(bool_neighborhood, rules, new_rule)
      else:
        perturbed[r,c] = rule_lookup(bool_neighborhood, rules, rules[1])

  return perturbed

# Rule lookup
def rule_lookup(neighborhood, rules, rule):

  bool_neighborhood = neighborhood.astype(bool).flatten()

  return cpl.nks_rule(bool_neighborhood, rule)

import cellpylib as cpl
import matplotlib.pyplot as plt
import numpy as np

# Parameters
init = [0,1,0,1,0,1,0,1]
rule1, rule2 = 131, 115
timesteps = 10

# Generate ECA pattern
def generate_eca(init, rules, timesteps):
  ca = cpl.evolve(np.array([init]), timesteps,
                 lambda n,c,t: cpl.nks_rule(n, rules[0])*cpl.nks_rule(n,rules[1]))
  return ca

# Perturb rule
# def perturb_rule(ca, rule_idx, new_rule):
#   return cpl.evolve(ca[0], ca.shape[0],
#                     lambda n,c,t: cpl.nks_rule(n,rules[0])
#                                if rule_idx != 0 else cpl.nks_rule(n,new_rule))


# Retrieve Observed market data
input_image = observed_original

# Plotting
ca = generate_eca(init, [rule1, rule2], timesteps)
perturbed = perturb_rule(ca, [rule1, rule2], 0, 130)

fig,ax = plt.subplots(1,3,figsize=(12,4))

ax[0].imshow(input_image)
ax[0].set_title('Original')

ax[1].imshow(ca)
ax[1].set_title(f'Rule {rule1},{rule2}')

ax[2].imshow(perturbed)
ax[2].set_title(f'Perturbed Rule {rule1}')

plt.show()



"""### Manifolds"""

from sklearn.datasets import make_swiss_roll
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

# Generate a Swiss roll dataset as a manifold embedded in 3D
X, color = make_swiss_roll(n_samples=1000)

# Apply TSNE to reduce to 2D while preserving distances
tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)
X_tsne = tsne.fit_transform(X)

# Plot the original 3D data and 2D embeddings
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))

ax1.scatter(X[:,0], X[:,1], X[:,2], c=color)
ax1.set_title("Original Data")

ax2.scatter(X_tsne[:,0], X_tsne[:,1], c=color)
ax2.set_title("TSNE Embedding")

plt.show()

"""## Last

### Single Rule
"""

INPUT_PATH

filenames = get_filenames(INPUT_PATH)

filenames