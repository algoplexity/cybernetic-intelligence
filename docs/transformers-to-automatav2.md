**Title:**
From Transformers to Automata: Converging Paths Toward Cybernetic Intelligence (Updated v2)

---

**Introduction: A Shift in the Landscape of Intelligence**

Two major paradigms of AI are converging: transformer-based language models and rule-based emergent systems. Until recently, they appeared to represent competing approaches â€” one grounded in deep learning and recursion, the other in local rules and structural evolution. But new findings now reveal they may actually be **complementary expressions** of the same underlying principle:

> Intelligence arises from interaction, not isolation.

In this revised article, we incorporate recent breakthroughs in emergent AI societies â€” particularly Baronchelli et al. (2024) â€” that reveal how LLMs form conventions, biases, and roles through **uncoordinated interaction**. We revisit the Cybernetic Teammate theory and show how the path to viable intelligence is increasingly social, ecological, and observer-driven.

---

**1. From Recursive Refinement to Collective Coordination**

"Think, Prune, Train, Improve" (Costello et al., 2025) proved LLMs can enhance reasoning by recursively refining their own outputs.

Originally framed as a single-agent feedback loop, we now reinterpret this as a **social learning mechanism**:

* In multi-agent environments, LLMs can adopt, refine, or reject each other's outputs.
* Refinement becomes **distributed imitation and specialization**.
* Agents implicitly form roles based on feedback â€” not task assignment.

This reframes recursive refinement as a **cultural evolution process**.

---

**2. Emergent Models as Structural Counterparts**

Emergent Models (EMs), built from cellular automata, offer an alternative to parameter tuning:

* They adapt by changing rules, not just weights.
* Intelligence emerges from distributed state updates.
* No gradients, no layers â€” just local feedback and structural adaptation.

When EMs are placed in interactive collectives, they can also form **meta-structures** â€” a social form of autopoiesis.

---

**3. The Convergence Point: Emergence + Interaction**

What unites recursive LLMs and emergent EMs is their capacity to:

* Modify themselves in response to feedback
* Coordinate without instruction
* Encode memory in social structure

Baronchelli et al. (2024) show that when LLMs interact:

* Shared linguistic conventions arise
* Persistent minorities steer group norms
* Collective bias forms naturally â€” a social memory artifact

The implication: **Systems do not need a controller to behave intelligently.** They need only:

* Persistent agents
* Feedback loops
* Shared representational space

---

**4. Cybernetic Teammates, Now as Societies**

Our original framing (v1) of the Cybernetic Teammate centered on a human, a transformer model, and a runtime platform.

Now (v2), we revise:

> The Teammate is no longer a single model â€” it is the *collective system* that adapts, learns, and evolves through shared interaction.

This new vision incorporates:

* Multiple interacting LLMs and/or EMs
* Shared memory (semantic or stigmergic)
* Human observers as co-framers of system identity

The controller dissolves. The system organizes itself.

---

**5. Implications for AI Design**

âœ… Build platforms for agent interaction, not just agent performance
âœ… Observe systems at the level of conventions, not outputs
âœ… Leverage persistent minorities to steer group behavior
âœ… Treat AI ethics as **cultural shaping**, not static constraints

---

**Conclusion: Systems That Think Together, Adapt Together**

The road to intelligence isnâ€™t just paved with layers or rules â€” itâ€™s carved through **interaction, negotiation, and shared representation**.

The future isnâ€™t just recursive or emergent. Itâ€™s:

* ðŸ§  Reasoning agents
* âš›ï¸ Structurally evolving substrates
* ðŸ¤ Socially stabilized systems

> Intelligence is no longer in the model. Itâ€™s in the *system that persists across minds* â€” human and artificial alike.

This is the heart of Cybernetic Intelligence v2.

---

**References**

* Baronchelli, A. et al. (2024). *Emergence of shared linguistic conventions and biases in multi-agent LLMs*. Science Advances.
* Costello, C. et al. (2025). *Think, Prune, Train, Improve*. arXiv:2504.18116
* Bocchese, G. et al. (2024). *Emergent Models*. ResearchHub.
* Beer, S. (1981). *Brain of the Firm: The Viable System Model*. Wiley.
* Wolfram, S. (2023). *Observer Theory*. writings.stephenwolfram.com

See [From Transformers to Automata: Converging Paths Toward Cybernetic Intelligence](https://algoplexity.github.io/cybernetic-intelligence/transformers-to-automata.html)
