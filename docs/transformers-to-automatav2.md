**Title:**
From Transformers to Automata: Converging Paths Toward Cybernetic Intelligence (Updated v2)

---

**Introduction: A Shift in the Landscape of Intelligence**

Two major paradigms of AI are converging: transformer-based language models and rule-based emergent systems. Until recently, they appeared to represent competing approaches — one grounded in deep learning and recursion, the other in local rules and structural evolution. But new findings now reveal they may actually be **complementary expressions** of the same underlying principle:

> Intelligence arises from interaction, not isolation.

In this revised article, we incorporate recent breakthroughs in emergent AI societies — particularly Baronchelli et al. (2024) — that reveal how LLMs form conventions, biases, and roles through **uncoordinated interaction**. We revisit the Cybernetic Teammate theory and show how the path to viable intelligence is increasingly social, ecological, and observer-driven.

---

**1. From Recursive Refinement to Collective Coordination**

"Think, Prune, Train, Improve" (Costello et al., 2025) proved LLMs can enhance reasoning by recursively refining their own outputs.

Originally framed as a single-agent feedback loop, we now reinterpret this as a **social learning mechanism**:

* In multi-agent environments, LLMs can adopt, refine, or reject each other's outputs.
* Refinement becomes **distributed imitation and specialization**.
* Agents implicitly form roles based on feedback — not task assignment.

This reframes recursive refinement as a **cultural evolution process**.

---

**2. Emergent Models as Structural Counterparts**

Emergent Models (EMs), built from cellular automata, offer an alternative to parameter tuning:

* They adapt by changing rules, not just weights.
* Intelligence emerges from distributed state updates.
* No gradients, no layers — just local feedback and structural adaptation.

When EMs are placed in interactive collectives, they can also form **meta-structures** — a social form of autopoiesis.

---

**3. The Convergence Point: Emergence + Interaction**

What unites recursive LLMs and emergent EMs is their capacity to:

* Modify themselves in response to feedback
* Coordinate without instruction
* Encode memory in social structure

Baronchelli et al. (2024) show that when LLMs interact:

* Shared linguistic conventions arise
* Persistent minorities steer group norms
* Collective bias forms naturally — a social memory artifact

The implication: **Systems do not need a controller to behave intelligently.** They need only:

* Persistent agents
* Feedback loops
* Shared representational space

---

**4. Cybernetic Teammates, Now as Societies**

Our original framing (v1) of the Cybernetic Teammate centered on a human, a transformer model, and a runtime platform.

Now (v2), we revise:

> The Teammate is no longer a single model — it is the *collective system* that adapts, learns, and evolves through shared interaction.

This new vision incorporates:

* Multiple interacting LLMs and/or EMs
* Shared memory (semantic or stigmergic)
* Human observers as co-framers of system identity

The controller dissolves. The system organizes itself.

---

**5. Implications for AI Design**

✅ Build platforms for agent interaction, not just agent performance
✅ Observe systems at the level of conventions, not outputs
✅ Leverage persistent minorities to steer group behavior
✅ Treat AI ethics as **cultural shaping**, not static constraints

---

**Conclusion: Systems That Think Together, Adapt Together**

The road to intelligence isn’t just paved with layers or rules — it’s carved through **interaction, negotiation, and shared representation**.

The future isn’t just recursive or emergent. It’s:

* 🧠 Reasoning agents
* ⚛️ Structurally evolving substrates
* 🤝 Socially stabilized systems

> Intelligence is no longer in the model. It’s in the *system that persists across minds* — human and artificial alike.

This is the heart of Cybernetic Intelligence v2.

---

**References**

* Baronchelli, A. et al. (2024). *Emergence of shared linguistic conventions and biases in multi-agent LLMs*. Science Advances.
* Costello, C. et al. (2025). *Think, Prune, Train, Improve*. arXiv:2504.18116
* Bocchese, G. et al. (2024). *Emergent Models*. ResearchHub.
* Beer, S. (1981). *Brain of the Firm: The Viable System Model*. Wiley.
* Wolfram, S. (2023). *Observer Theory*. writings.stephenwolfram.com

See [From Transformers to Automata: Converging Paths Toward Cybernetic Intelligence](https://algoplexity.github.io/cybernetic-intelligence/transformers-to-automata.html)
